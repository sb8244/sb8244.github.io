<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Stephen Bussey's Software Engineering Blog</title>
  <id>https://stephenbussey.com</id>
  <link href="https://stephenbussey.com"/>
  <link href="https://stephenbussey.com/feed.xml" rel="self"/>
  <updated>2019-05-10T13:00:00-04:00</updated>
  <author>
    <name>Stephen Bussey</name>
  </author>
  <entry>
    <title>Useful Elixir Patterns from Real-world Side Project</title>
    <link rel="alternate" href="https://stephenbussey.com/2019/05/10/useful-elixir-patterns-from-real-world-side-project.html"/>
    <id>https://stephenbussey.com/2019/05/10/useful-elixir-patterns-from-real-world-side-project.html</id>
    <published>2019-05-10T13:00:00-04:00</published>
    <updated>2019-05-10T16:35:01-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;I believe that one of the best ways to push new practices is to work on a real-world project that we
can afford to experiment on. We can push the boundary in the toy project while still seeing the results
of the decisions in a production environment with real users. I&amp;rsquo;ve been fortunate to be able to ship
several applications like this at SalesLoft. The latest one that we&amp;rsquo;ll look at today is our internal OKR app.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll walk through this project and see several different patterns that I like. Some of these patterns
have been used in several different projects of mine and have held up well. Others were new experiments
that I hope to use again in the future.&lt;/p&gt;

&lt;p&gt;The source code for the application can be found on &lt;a href="https://github.com/sb8244/okr_app_pub" target="_blank"&gt;Github&lt;/a&gt;. The useful
part is the code and tests, less so the specific functionality.&lt;/p&gt;

&lt;h1&gt;Context Usage&lt;/h1&gt;

&lt;p&gt;Contexts, at least as I use them, are all about establishing an application domain and keeping
the interfaces small and useful for other parts of the system to use. I&amp;rsquo;ve done this in the past but
really pushed it for this project by having no function usage other than top level modules. This
pattern allows us to have a well-defined interface for the application, which makes it simpler for both
us and others to modify the code and understand the consequences.&lt;/p&gt;

&lt;p&gt;As an example, the following would not be acceptable:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;MyApp.SomeContext.ASpecificQuery.execute(params)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instead, I would prefer this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;MyApp.SomeContext.a_query(params)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;All of my contexts live under the &lt;code&gt;OkrApp&lt;/code&gt; module. You can see a list of them in the &lt;a href="https://github.com/sb8244/okr_app_pub/tree/master/lib/okr_app" target="_blank"&gt;okr_app folder&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I started off the application by writing code directly in the context. Some of this is still seen because
I didn&amp;rsquo;t go back through and change everything once I solidified on what I wanted. In the end, I found
that &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/analytics.ex#L5" target="_blank"&gt;function delegates&lt;/a&gt;
allowed the context to be very easy to digest and I could write tests for the underlying modules in distinct
files.&lt;/p&gt;

&lt;p&gt;The hardest part of this pattern, that I haven&amp;rsquo;t figured out yet, is how to handle Ecto schemas between
contexts. Sometimes, a context needs to leak out. For example, a &lt;code&gt;User&lt;/code&gt; schema may need to be referenced
by the &lt;code&gt;AnalyticsEvent&lt;/code&gt; schema (as seen &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/analytics/analytics_event.ex#L11" target="_blank"&gt;here&lt;/a&gt;).
I found this acceptable because I wasn&amp;rsquo;t invoking logic outside of the context interface.&lt;/p&gt;

&lt;p&gt;The advantage of Context came out when I built the &lt;a href="https://github.com/sb8244/okr_app_pub/tree/master/lib/okr_app/mailer" target="_blank"&gt;mailer&lt;/a&gt;.
I found it very simple to add in this new code without worrying about anything breaking. I was also to extract concepts
specific to the mailer (such as &lt;code&gt;Recipient&lt;/code&gt;) rather than relying on generic modules prone to change such as &lt;code&gt;User&lt;/code&gt;.&lt;/p&gt;

&lt;h1&gt;Isolated Logic (Context) for SCIM&lt;/h1&gt;

&lt;p&gt;One of the requirements for this project was SCIM (System for Cross-domain Identity Management). We use Okta internally and
they have a lot of docs on how to write a SCIM integration. I didn&amp;rsquo;t want the details of SCIM leaking into the system too
heavily. I was able to leverage a SCIM Context to achieve this goal in a way that I am pretty satisfied with.&lt;/p&gt;

&lt;p&gt;SCIM has all of its web functionality extracted into a module called &lt;code&gt;Scim.Web&lt;/code&gt;. &lt;code&gt;Phoenix.Router&lt;/code&gt; is used to provide the
appropriate endpoint definitions, but the integration happens in a simple &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/scim/web/plug.ex#L13" target="_blank"&gt;Plug&lt;/a&gt;
which is used by &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app_web/router.ex#L43" target="_blank"&gt;&lt;code&gt;OkrAppWeb.Router&lt;/code&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The entire &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/scim/web/users_controller.ex#L9" target="_blank"&gt;SCIM controller&lt;/a&gt; leverages
a behavior passed into it. This is the &lt;a href="https://en.wikipedia.org/wiki/Strategy_pattern" target="_blank"&gt;strategy pattern&lt;/a&gt; at work.
I didn&amp;rsquo;t create a specific &lt;code&gt;Behaviour&lt;/code&gt; requirement for this module but probably should have, because it has an expected
interface.&lt;/p&gt;

&lt;p&gt;The actual SCIM application integration happens in &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/users_scim.ex" target="_blank"&gt;UsersScim&lt;/a&gt;.
This code is a bit ugly since I didn&amp;rsquo;t clean it up too much, but it&amp;rsquo;s nice that the implementation doesn&amp;rsquo;t leak into my
application API nor does it leak into other contexts.&lt;/p&gt;

&lt;h1&gt;ListQuery Module&lt;/h1&gt;

&lt;p&gt;I really like Ecto&amp;rsquo;s API for querying data, but I have found it cumbersome to build up dynamic queries from API params easily.
I wrote a &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/query/list_query.ex" target="_blank"&gt;&lt;code&gt;ListQuery&lt;/code&gt;&lt;/a&gt; some time ago that I brought into this project.&lt;/p&gt;

&lt;p&gt;The ListQuery is used to take provided &lt;code&gt;params&lt;/code&gt; and &lt;code&gt;opts&lt;/code&gt; and turns it into an Ecto compatible query. Sometimes advanced
queries are required and I devised a small way to do that by stripping certain &lt;code&gt;params&lt;/code&gt; and then reapplying them. You can
see that &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/objectives/store/cycle_store.ex#L11" target="_blank"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m able to leverage a &lt;code&gt;ListQuery&lt;/code&gt; powered function in &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app_web/controllers/api/objective_link_controller.ex#L11" target="_blank"&gt;various controllers&lt;/a&gt;
by passing in the user params. If you use this pattern in an environment with non-friendly users, you should probably sanitize
the input to not leak any information to the client.&lt;/p&gt;

&lt;h1&gt;SimpleEctoStore Module&lt;/h1&gt;

&lt;p&gt;My contexts use &lt;code&gt;defdelegate&lt;/code&gt; to send queries to a different module. I called the module a &amp;ldquo;store&amp;rdquo; and found myself
&lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/objectives.ex#L13" target="_blank"&gt;delegating to them often&lt;/a&gt;.
Writing the same code again and again in the store became a bit cumbersome. Often, I would be writing the most
simple code possible with just the module name changed.&lt;/p&gt;

&lt;p&gt;My solution to this copy/paste problem was to build a macro powered &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/store/simple_ecto_store.ex" target="_blank"&gt;&lt;code&gt;SimpleEctoStore&lt;/code&gt;&lt;/a&gt;.
Each usage of &lt;code&gt;SimpleEctoStore&lt;/code&gt; involved passing in the schema module as well as what methods were desired to be
pulled in. You can see this &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/objectives/store/objective_link_store.ex#L2" target="_blank"&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This allowed me to remove the boiler plate for a large number of ecto stores. If I used a concept like stores again,
I would definitely repeat this one.&lt;/p&gt;

&lt;h1&gt;Things that didn&amp;rsquo;t work as well&lt;/h1&gt;

&lt;p&gt;One of the biggest pain points I had was defining how I wanted my JSON API to work. At work, I follow the philosophy of very focused
endpoints that don&amp;rsquo;t preload many models together. This is for performance and flexibility reasons. Doing that in this project
made it much more complex for me and was going to take time that I didn&amp;rsquo;t want to spend. The end result here is that I
have a massive endpoint called &amp;ldquo;Okr&amp;rdquo; that &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app_web/serializers/okr.ex" target="_blank"&gt;embeds many associations&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The preload for my Okr endpoint is &lt;a href="https://github.com/sb8244/okr_app_pub/blob/master/lib/okr_app/objectives/okr_preloader.ex" target="_blank"&gt;pretty gnarly&lt;/a&gt; as
well. However, I was thrilled to be able to pass queries into the preload clauses which means that I removed the risk of
accidentally leaking data that is queried out of the system but then not handled properly by me in Elixir.&lt;/p&gt;

&lt;p&gt;Another thing that I still feel awkward about is a context&amp;rsquo;s schema referencing a different context&amp;rsquo;s schema. I wanted to
remove this but couldn&amp;rsquo;t figure out how to do so in a way I liked.&lt;/p&gt;

&lt;h1&gt;Summary&lt;/h1&gt;

&lt;p&gt;Contexts allowed for a focused API between parts of an application. Using them saved me some mental gymnastics as I was
developing the application. I was particularly happy with how I was able to isolate the sort of whacky SCIM API via
focused context modules.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ListQuery&lt;/code&gt; and &lt;code&gt;SimpleEctoStore&lt;/code&gt; both made my life easier while defining my ecto based queries and stores. These are generically
applicable modules that could be brought into other applications if needed.&lt;/p&gt;

&lt;p&gt;I am really happy overall with how this project turned out. It is easy to read through nearly 6 months after I&amp;rsquo;ve originally
built it and has been running without any Elixir issues since that time. I&amp;rsquo;ll be applying these patterns to future projects,
for sure, and hope you are able to get some value from it!&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading! I&amp;rsquo;ll be teaching a class at ElixirConf US about building scalable real-time systems in Elixir. I&amp;rsquo;ve been
focused a lot on this topic so I&amp;rsquo;m pretty thrilled to share what I&amp;rsquo;ve learned. I believe that registration will open
soon.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Monolith to Microservice Without Downtime — A Production Story</title>
    <link rel="alternate" href="https://stephenbussey.com/2019/03/01/monolith-to-microservice-without-downtime-a-production-story.html"/>
    <id>https://stephenbussey.com/2019/03/01/monolith-to-microservice-without-downtime-a-production-story.html</id>
    <published>2019-03-01T17:35:00-05:00</published>
    <updated>2019-03-01T17:38:19-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;I am cross-posting for an article that I published on &lt;a href="https://medium.com/salesloft-engineering/monolith-to-microservice-without-downtime-a-production-story-652c9b82f03e" target="_blank"&gt;SalesLoft&amp;rsquo;s Medium blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Rather than copying the content over to this blog, I&amp;rsquo;m going to point you at the above Medium post. However, here are the lessons learned from the process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Migrating from monolith to microservice is not easy. In fact, it involved a lot of nuance in the coding and planning that had to be a forethought and not an afterthought.&lt;/li&gt;
&lt;li&gt;Stability for customers is the most important part of a refactor like this; our product exists to serve our customers and not to be a microservice-powered entity.&lt;/li&gt;
&lt;li&gt;Finding the seam in the monolith is important when it comes to stability. If your new code, which shouldn’t be running until it’s ready, causes old requests to fail…that is a problem.&lt;/li&gt;
&lt;li&gt;The timeline was significantly longer than I anticipated. This is important because we have to prioritize refactoring old code against developing new features and fixing bugs. On the flip side…&lt;/li&gt;
&lt;li&gt;The slower timeline helped us ensure rock solid stability. We had zero stability concern on release day, which turned out to be like any other normal day.&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>Distributed In-Memory Caching in Elixir</title>
    <link rel="alternate" href="https://stephenbussey.com/2019/01/29/distributed-in-memory-caching-in-elixir.html"/>
    <id>https://stephenbussey.com/2019/01/29/distributed-in-memory-caching-in-elixir.html</id>
    <published>2019-01-29T17:04:00-05:00</published>
    <updated>2019-01-30T10:32:53-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;I&amp;rsquo;ve been working with implementing our PushEx server at SalesLoft (a bit later than I thought I&amp;rsquo;d have time to) and one
of the challenges has been to map user identities in our authentication token to a legacy identity that we use in our
push channels. This is as simple as an HTTP call, but it is also something that could potentially burst very hard and cause
a large number of downstream HTTP calls. In order to help alleviate this, the identity -&amp;gt; secondary identity will be cached.&lt;/p&gt;

&lt;p&gt;I would typically just throw a cache in redis or memcached, but I really wanted to reach for something simpler in this situation.
My goals for this project are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;No external databases introduced (there are none currently on our PushEx implementation)&lt;/li&gt;
&lt;li&gt;Caching can be persistent between deploys (we roll our deploys so some pods are always online)&lt;/li&gt;
&lt;li&gt;Caching is conceptually simple in case it needs debugged by another engineer in the future&lt;/li&gt;
&lt;li&gt;Identity mappings will be stable between services, so time variations are not required. However:&lt;/li&gt;
&lt;li&gt;Caching will use a TTL to prevent really stale values from being used&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;m going to walk through the different options I looked at and what I ended up on. The options I passed on aren&amp;rsquo;t necessarily bad,
they just ended up being operationally or conceptually more difficult than I needed.&lt;/p&gt;

&lt;h1&gt;Swarm&lt;/h1&gt;

&lt;p&gt;There was a great talk in the Atlanta Elixir Meetup recently about using Swarm to manage processes across a cluster. I really liked
a few things that the presentation demonstrated:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Processes are stable such that restarting a node with the same identity will put the process back on that node&lt;/li&gt;
&lt;li&gt;Processes are capable of handing themselves off to another node&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;My initial plan was to put Cachex or another store in sharded processes that are distributed across the cluster. However, I soon
realized that passing off this ets state may be fairly complex and so I ended up looking at the cache as a simple in-process memory
map. That is actually fine with me, but some other things didn&amp;rsquo;t work out for it.&lt;/p&gt;

&lt;p&gt;The biggest issue that I ran into was that process hand-off became fairly complex to implement. I never actually got that working
properly after ~4 hours of work on it. Another bigger issue is that there is no process state replication. This means that my shard
values would have to pass themselves off fully to another node between the time that the node is told to shut down and the near future.
If the node was forcibly killed before then, the data would be lost and the cache would be re-populated.&lt;/p&gt;

&lt;p&gt;I ended up moving on from this to trying out the next solution because it seemed like I was getting myself into a solution I didn&amp;rsquo;t need.
That will be a theme in this blog post: there is nothing particularly wrong with technology X, but the trade-offs it brings may be more
than worth it for the particular use case I&amp;rsquo;m working with.&lt;/p&gt;

&lt;h1&gt;Delta CRDT&lt;/h1&gt;

&lt;p&gt;After talking with my colleague Dan about this topic (he will be presenting on distributed state at Lonestar Elixir Conf and it will be awesome),
he suggested looking at DeltaCRDT as a potential solution. I really liked this library for a few reasons:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;State is replicated across the cluster, so shutdowns are not frantic&lt;/li&gt;
&lt;li&gt;CRDT gives a lot of benefit around time variation in the cluster (node A has a different value than node B at a point in time)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We ended up getting a working solution that used the DeltaCRDT library. Our code looked something like this (don&amp;rsquo;t use this code):&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;defmodule SalesloftPusher.AccountLookupCache.Monitor do
  use GenServer

  def start_link(_) do
    GenServer.start_link(__MODULE__, [], name: __MODULE__)
  end

  def init(_) do
    :net_kernel.monitor_nodes(true)

    {neighbors, []} = :rpc.multicall(Node.list, Process, :whereis, [AccountLookupCache])
    DeltaCrdt.add_neighbours(AccountLookupCache, neighbors)

    {:ok, []}
  end

  # Callbacks

  def handle_info({:nodeup, node}, state) do
    handle_info({:retrynodeup, node, 0}, state)
  end

  def handle_info({:retrynodeup, node, count}, state) do
    pid = :rpc.call(node, Process, :whereis, [AccountLookupCache])

    if pid == nil do
      IO.puts &amp;quot;Node is up, but app not booted, retry = #{count}&amp;quot;
      Process.send_after(self(), {:retrynodeup, node, count + 1}, 500)
    else
      IO.puts &amp;quot;Node is now up #{node} #{inspect(pid)}&amp;quot;
      DeltaCrdt.add_neighbours(AccountLookupCache, [pid])
    end

    {:noreply, state}
  end

  def handle_info({:nodedown, _node}, state) do
    {:noreply, state}
  end
end

usage:

DeltaCrdt.read(AccountLookupCache)
DeltaCrdt.mutate(AccountLookupCache, :add, [&amp;quot;1111/2&amp;quot;, &amp;quot;4&amp;quot;])
DeltaCrdt.read(AccountLookupCache)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is a pretty slick library and the setup was fairly simple. This code may have some edge cases in it but we ran into
some performance issues with larger data sets and moved onto another solution. While we did end up moving on from it, the
author has been working hard on a refactor to improve the speed of the data structure. What&amp;rsquo;s he is doing is way beyond my
understanding of CRDTs and is pretty inspiring open-source work.&lt;/p&gt;

&lt;p&gt;This issue got me thinking and I realized that I didn&amp;rsquo;t need a lot of the benefits of the CRDT. I wanted replication across
the cluster, but my values are stable and so time variations won&amp;rsquo;t be a factor. I would most likely have stuck with DeltaCRDT
at this point if that was a factor, but I ended up moving onto my current solution.&lt;/p&gt;

&lt;h1&gt;Cachex + pg2 Replication&lt;/h1&gt;

&lt;p&gt;My final solution involves a tried and true solution around Cachex + pg2. I&amp;rsquo;ve &lt;a href="/2018/02/17/pg2-basics-use-process-groups-for-orchestration-across-a-cluster.html" target="_blank"&gt;written about pg2&lt;/a&gt;
in the past and have used it successfully in production on several projects. It essentially lets us
place our cache processes in a group across the cluster and reference the remote cache processes as a pid list.&lt;/p&gt;

&lt;p&gt;The solution presented below utilizes Cachex for all local set/get/stat, and passes messages containing
sets to the cluster using &lt;code&gt;send&lt;/code&gt;. When the cache process starts it notifies all neighbors in pg2
that it would like a dump of the state and then writes that into Cachex. Here are some strengths
and weaknesses of the solution:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;+ Boot based (rather than shutdown) based replication so that nodes do not lose data when they go down&lt;/li&gt;
&lt;li&gt;+ Cachex for local cache management (so we get all of that library&amp;rsquo;s benefits)&lt;/li&gt;
&lt;li&gt;+ Efficient writing and loading of an export. In testing it took less than 3 seconds for a 1,000,000 key cache locally (higher across network)&lt;/li&gt;
&lt;li&gt;- The entire cluster being down will cause cache data loss and an increase in misses&lt;/li&gt;
&lt;li&gt;- There is no consensus on what the right cache is, it&amp;rsquo;s best attempt&lt;/li&gt;
&lt;li&gt;- Possible flood of binary across network on boot with many nodes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The biggest disadvantage is the last one and I think it will be fixed before I take this code into production. It
is a purely effort based blocker (I need to write the code) and conceptually will work just fine.&lt;/p&gt;

&lt;h1&gt;The Code&lt;/h1&gt;

&lt;p&gt;The code is on a gist due to being fairly long: &lt;a href="https://gist.github.com/sb8244/371335946d444bd8c5786571cacef4d6" target="_blank"&gt;The Code&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The end result is a straightforward set/get interface which handles all of the distribution and caching.
I did a few basic performance tests of the system by throwing 10k, 50k, 500k, 1000k k/v
pairs into the cache and seeing how it performed. Writes and distribution were incredibly fast and rebooting
the application caused cache availability within a few seconds, well before the app would finish booting for
kubernetes health checks. There was one caveat I noticed which is that memory usage spiked while loading
the dumps from remote servers. I believe that the best solution here will involve me changing to a solution
that collects the size of each remote cache and selects the top 1 or 2 sized caches. That will prevent N
servers from sending full cache dumps and only 1 or 2.&lt;/p&gt;

&lt;h1&gt;Summary&lt;/h1&gt;

&lt;p&gt;In summary, three different potential solutions were evaluated for this distributed caching problem. While
the first two options utilize great libraries and would be possible to build on, the trade-offs were too much
for the simplicity of my needs.&lt;/p&gt;

&lt;p&gt;When working on a software project like this, considering what your exact needs are is important and may actually
lead you away from the typical libraries into a different solution. It may seem obvious for many, but it is very
easy to get caught up in the libraries that we&amp;rsquo;re hearing about rather than what is best for our particular use case.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading! I&amp;rsquo;ll be speaking at &lt;a href="https://lonestarelixir.com/2019/" target="_blank"&gt;Lonestar ElixirConf&lt;/a&gt; about bringing Elixir to production,
looking at both human and tech challenges in doing so.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Understanding Compile Time Dependencies in Elixir - A Bug Hunt</title>
    <link rel="alternate" href="https://stephenbussey.com/2019/01/03/understanding-compile-time-dependencies-in-elixir-a-bug-hunt.html"/>
    <id>https://stephenbussey.com/2019/01/03/understanding-compile-time-dependencies-in-elixir-a-bug-hunt.html</id>
    <published>2019-01-02T21:59:00-05:00</published>
    <updated>2019-01-11T16:18:07-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;This blog post will cover a fairly trivial but still interesting problem that I encountered at work today. I think it&amp;rsquo;s worth writing about simply because it&amp;rsquo;s a bit non-obvious and will probably happen to other people as well. It also is a good time to reinforce our understanding of how the Elixir compiler works and why the order of things matters.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;The issue started after upgrading one of our repositories to the latest Elixir version (from 1.6) and upgrading Distillery from 1.5 -&amp;gt; 2.0. The problem manifested itself as our instrumentation disappearing in DataDog. The graphs was there before the deployment, then immediately became empty after.&lt;/p&gt;

&lt;p&gt;The immediate thought is that something could have been wrong with 1.7 or the upgrade libraries (and not something we did). However, this seems unlikely given that Elixir 1.7 has been out in the wild for a while now and has had time to get any kinks worked out (and something this major would be unlikely anyways). We power our instrumentation with &lt;a href="https://github.com/discordapp/instruments/" target="_blank"&gt;Instruments&lt;/a&gt; as seen in a &lt;a href="/2018/09/24/elixir-probes-replacing-elixometer.html" target="_blank"&gt;past post&lt;/a&gt; and so we verified that the application was started and configured with all of our probes&amp;hellip;everything was visibly okay on this front.&lt;/p&gt;

&lt;p&gt;After confirming that instruments should be working, we noticed that DataDog was reporting some stats for our application that looked an awful lot like what we wanted&amp;hellip;it was just missing our &amp;ldquo;.probes&amp;rdquo; namespace. The problem isn&amp;rsquo;t that the stats weren&amp;rsquo;t reporting, but that they were reporting without our &lt;code&gt;probe_prefix&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;The Code Problem&lt;/h2&gt;

&lt;p&gt;Inside of Instruments, there is a line of code which loads the provided probe prefix and places it into a module attribute:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# https://github.com/discordapp/instruments/blob/89a620d181ba4a04ed0ac01c47057c018d645428/lib/probe/definitions.ex#L11
@probe_prefix Application.get_env(:instruments, :probe_prefix)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This line of code happens inside of a &lt;code&gt;defmodule&lt;/code&gt;, which means that it is read from at compile time and not at run-time. It would be possible to use &lt;code&gt;Application.get_env/2&lt;/code&gt; at run-time using something like &lt;code&gt;def probe_prefix&lt;/code&gt;, but there is nothing wrong with the module attribute approach.&lt;/p&gt;

&lt;p&gt;In Distillery 1, all config was provided at compile time and &lt;code&gt;probe_prefix&lt;/code&gt; would always be present. In Distillery 2 (with the awesome new config providers), config can optionally be provided at run time; this simplifies and fixes quite a few deployment quirks. Our standard for Distillery 2 config providers has been to move &lt;code&gt;config/prod.exs&lt;/code&gt; to &lt;code&gt;rel/config/runtime.exs&lt;/code&gt;.&lt;/p&gt;

&lt;h2&gt;The Fix&lt;/h2&gt;

&lt;p&gt;In hindsight, we should not have moved the entire contents of &lt;code&gt;config/prod.exs&lt;/code&gt; into our config provider. As Paul mentions in his &lt;a href="https://dockyard.com/blog/2018/08/23/announcing-distillery-2-0" target="_blank"&gt;release blog post&lt;/a&gt;, &amp;ldquo;You can still use all of the config files under config/ in your project, but you should use those for compile-time config and default values only&amp;rdquo;.&lt;/p&gt;

&lt;p&gt;The fix is as simple as making sure our &lt;code&gt;runtime.exs&lt;/code&gt; file only has dynamic values in it. This means that we provide a &lt;code&gt;config/prod.exs&lt;/code&gt; file for static configuration, and a &lt;code&gt;rel/config/runtime.exs&lt;/code&gt; file for dynamic configuration.&lt;/p&gt;

&lt;h2&gt;Compilation vs Run-time&lt;/h2&gt;

&lt;p&gt;The reason that I liked this small bug is that it reinforces understanding of compilation and how we can very quickly end up blurring the line between run-time and compile-time. As users and authors of code, we have to be cognizant of where are values are coming from and where provided values are going. It often will be perfectly &amp;ldquo;okay&amp;rdquo; to do things incorrectly (because there are many situations where it wouldn&amp;rsquo;t be a problem), but it can be difficult to track down when it is not okay. In particular, this issue looked like &lt;code&gt;probe_prefix&lt;/code&gt; was setup correctly, and only become clear through reading of the source code that it was not setup correctly.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading! I&amp;rsquo;ll be speaking at &lt;a href="https://lonestarelixir.com/2019/" target="_blank"&gt;Lonestar ElixirConf&lt;/a&gt; about bringing Elixir to production, looking at both human and tech challenges in doing so.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Announcing PushEx: Open-Source WebSocket Push Server in Elixir</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/12/02/announcing-pushex-open-source-websocket-push-server-in-elixir.html"/>
    <id>https://stephenbussey.com/2018/12/02/announcing-pushex-open-source-websocket-push-server-in-elixir.html</id>
    <published>2018-12-02T15:00:00-05:00</published>
    <updated>2019-01-02T21:43:58-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;I&amp;rsquo;m happy to announce the open-sourcing of a project that I&amp;rsquo;ve been putting a good deal of time and effort into, &lt;a href="https://github.com/pushex-project/pushex" target="_blank"&gt;PushEx&lt;/a&gt;. PushEx is a WebSocket push server built in Elixir; it allows you to send payloads from your servers to your users in real-time. In this post, I will go in-depth about the problem PushEx solves, why I&amp;rsquo;m excited about it, and why Elixir is perfect for the problem space.&lt;/p&gt;

&lt;h1&gt;The Problem&lt;/h1&gt;

&lt;p&gt;As consumers of an online web application use the application, asynchronous processes may take place that the user needs alerted to. Some examples of this include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Notifying a user when they get a new message&lt;/li&gt;
&lt;li&gt;Alerting the user when their multi-minute import finishes&lt;/li&gt;
&lt;li&gt;Updating the frontend website as backend data models are updated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;WebSockets allow an elegant solution to this problem because they enable the backend servers to maintain a direct connection to the user. The servers can then send data to the connected users nearly instantly.&lt;/p&gt;

&lt;p&gt;However, WebSockets bring about their own problems. The web server must be capable of handling all of the connections and keeping them alive every so often. In a production deployment, multiple servers must also be able to have knowledge about each other, because the user may be connected to server A but the request for a push goes through server B. Phoenix and Elixir, the foundation that PushEx leverages, provide excellent solutions to these problems.&lt;/p&gt;

&lt;h1&gt;Elixir, A Great Solution&lt;/h1&gt;

&lt;p&gt;Elixir is an excellent language for solving the problem of WebSockets. Some properties of Elixir that are great for this problem are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Parallel processing power for efficient handling of many connections&lt;/li&gt;
&lt;li&gt;Built-in networking between multiple servers in a deployment&lt;/li&gt;
&lt;li&gt;Ability to hold very large sets of processes (supports many connections)&lt;/li&gt;
&lt;li&gt;Incremental garbage collection per process (many connections won&amp;rsquo;t freeze at the same time)&lt;/li&gt;
&lt;li&gt;Error separation between processes (connections won&amp;rsquo;t crash each other)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Phoenix leverages the power of Elixir to provide an excellent WebSocket solution, and PushEx provides these same benefits because it is built using Phoenix Channels. In fact, Phoenix has been benchmarked at being able to support over 2 million connections on a single large box. While this is a fun benchmark, real world implementations will often have many servers networked together for efficiency, scalability, and redundancy. Phoenix provides a solution to the problems that come with distributed servers through &amp;ldquo;Presence&amp;rdquo;, a mathematically efficient solution to knowing the state of the distributed WebSockets.&lt;/p&gt;

&lt;h1&gt;Challenging to Bring to Production&lt;/h1&gt;

&lt;p&gt;Despite the effectiveness of Elixir and Phoenix for WebSockets, developing a production-ready push server is not a trivial task. Throughout the development of PushEx, an &lt;a href="https://github.com/phoenixframework/phoenix/pull/3141" target="_blank"&gt;improvement&lt;/a&gt; was found/developed to improve Phoenix&amp;rsquo;s JS client availability and the properties of many simultaneous connections were &lt;a href="https://elixirforum.com/t/phoenix-presence-mailbox-full/15139/13" target="_blank"&gt;examined&lt;/a&gt;. This work helps make PushEx production-ready and scalable to a large number of clients.&lt;/p&gt;

&lt;p&gt;While there are large companies using WebSockets in production successfully, it is easy to see that small details can be missed. The goal with PushEx is to identify, solve, document, and educate on these small details.&lt;/p&gt;

&lt;p&gt;PushEx seeks to make developing your production-ready push server easy! The &lt;a href="https://hexdocs.pm/push_ex/standalone.html#content" target="_blank"&gt;Getting Started - Standalone Installation guide&lt;/a&gt; allows you to get up and running in less than 10 steps, with only a bit of application-specific code needing developed.&lt;/p&gt;

&lt;h1&gt;Using PushEx&lt;/h1&gt;

&lt;p&gt;PushEx has been designed to be easy to setup and will be comfortable for Elixir developers. There are, however, quite a few guides written that will help make the process of developing and deploying PushEx easier. You can find these guides on &lt;a href="https://hexdocs.pm/push_ex/readme.html" target="_blank"&gt;hexdocs.pm&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;PushEx is currently in a 1.0.0 release candidate. An implementation has been developed for use in production at SalesLoft, and will be tested there within 30 days. Once it is in production, the 1.0.0 release will be shipped. I do not anticipate much changing between now and then, as the core system is similar to what is already in use on another internal project.&lt;/p&gt;

&lt;h1&gt;Giving Back to Elixir Community&lt;/h1&gt;

&lt;p&gt;Elixir and Phoenix are providing the solid backbone of PushEx and help to make it great. To that end, I want to invite the community to ask any questions they have on the PushEx project so that they may have some of their challenges solved. Please feel free to ask &lt;strong&gt;any&lt;/strong&gt; question on the &lt;a href="https://github.com/pushex-project/pushex/issues" target="_blank"&gt;PushEx Issue Tracker&lt;/a&gt; regarding any code or ideas in the project. I will personally read and answer each one to help provide back to the community.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Explore PushEx on:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://github.com/pushex-project" target="_blank"&gt;Github&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://hex.pm/packages/push_ex" target="_blank"&gt;Hex&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>Elixir Probes - Replacing Elixometer</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/09/24/elixir-probes-replacing-elixometer.html"/>
    <id>https://stephenbussey.com/2018/09/24/elixir-probes-replacing-elixometer.html</id>
    <published>2018-09-23T21:44:00-04:00</published>
    <updated>2019-01-02T21:43:58-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;It&amp;rsquo;s been a while since my last post. I&amp;rsquo;ve been chipping away at Elixir still, fortunately, focusing on making sure that other teams at SalesLoft are best equipped to build Elixir microservices. One of the most common items that need implemented on every Elixir project is a set of Datadog metrics. These metrics provide both VM health and application specific info.&lt;/p&gt;

&lt;h1&gt;Elixometer&lt;/h1&gt;

&lt;p&gt;Until now, all apps at SalesLoft have shipped with using Elixometer as an instrumentation service in our Elixir apps. Elixometer has a variety of methods that allow collection of stats and can report to a StatsD server. It also has a variety of problems:&lt;/p&gt;

&lt;h4&gt;1. The mix.exs entry for Elixometer is quite involved.&lt;/h4&gt;

&lt;p&gt;There seem to be some incompatiblies in the various libraries that have been released over time. Here is my current Elixometer mix.exs entry:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# start exometer; force &amp;quot;correct&amp;quot; modules due to elixometer not compiling properly
{:elixometer, &amp;quot;~&amp;gt; 1.2&amp;quot;},
{:lager, &amp;quot;&amp;gt;= 3.2.1&amp;quot;, override: true},
{:exometer, github: &amp;quot;Feuerlabs/exometer&amp;quot;},
{:exometer_core, &amp;quot;~&amp;gt;1.4.0&amp;quot;, override: true},
{:amqp_client, git: &amp;quot;https://github.com/dsrosario/amqp_client.git&amp;quot;, branch: &amp;quot;erlang_otp_19&amp;quot;, override: true},
# end exometer
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I haven&amp;rsquo;t even tried updating these because it took me several days to get a working config.&lt;/p&gt;

&lt;h4&gt;2. Elixometer includes libraries that are outside of instrumentation.&lt;/h4&gt;

&lt;p&gt;For instance, &lt;code&gt;lager&lt;/code&gt; is a listed dependency. This may not manifest as a problem in your project, but it could also be hiding from you. I discovered that including lager&amp;rsquo;s error logger module would clear out all of the other SASL error loggers, which is how Bugsnag was included. This meant that Bugsnag was being forcibly removed without my knowledge. The solution here was to disable lager&amp;rsquo;s error logger.&lt;/p&gt;

&lt;h4&gt;3. Elixometer is fairly complex to setup and use.&lt;/h4&gt;

&lt;p&gt;This has been a complaint both across the team and also on my own projects.&lt;/p&gt;

&lt;p&gt;I once wanted to report a simple count to Datadog and plot a rate of change. After 1-2 days of trying to figuring out why it was not working, I discovered that all stats report as gauges unless a complex setup is used to specify the reporting type&amp;hellip;I ended up using a different StatsD library (Statix) at that point.&lt;/p&gt;

&lt;h1&gt;Instruments - Elixometer&amp;rsquo;s Replacement&lt;/h1&gt;

&lt;p&gt;Going forward, I will be using the &lt;a href="https://github.com/discordapp/instruments" target="_blank"&gt;Instruments&lt;/a&gt; library to report probed metrics to Datadog. I will be using &lt;a href="https://github.com/lexmag/statix" target="_blank"&gt;Statix&lt;/a&gt; to report non-probed application metrics to Datadog.&lt;/p&gt;

&lt;p&gt;A probe is a bit of code that runs on a defined interval and reports the statistics on each run. An example of this is asking for VM memory utilization every 1s and sending that to StatsD. Instruments makes defining probes very easy, and I&amp;rsquo;m going to share my standard configuration.&lt;/p&gt;

&lt;h2&gt;Instruments Setup&lt;/h2&gt;

&lt;p&gt;I followed the guide on Github to setup Instruments in my application. Outside of the recommended config, I did find that reporting to the standard &lt;code&gt;Logger&lt;/code&gt; module during testing makes a ton of sense. To do that, I placed the following in &lt;code&gt;config/text.exs&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;config :instruments, reporter_module: Instruments.StatsReporter.Logger
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;My other config looks like:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;config :statix,
  prefix: &amp;quot;okr_app.#{Mix.env}&amp;quot;,
  host: System.get_env(&amp;quot;STATSD_HOST&amp;quot;),
  port: String.to_integer(System.get_env(&amp;quot;STATSD_PORT&amp;quot;) || &amp;quot;8125&amp;quot;),
  disabled: System.get_env(&amp;quot;STATSD_HOST&amp;quot;) == nil

config :instruments,
  fast_counter_report_interval: 100,
  probe_prefix: &amp;quot;probes&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Instruments Probe Definition&lt;/h2&gt;

&lt;p&gt;Probes are defined in Instruments a bit differently than in Elixometer. Elixometer utilizes a static configuration, but I cannot find such an option for Instruments. I defined probes in my &lt;code&gt;application.ex&lt;/code&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;def setup_probes() do
  # I allow instruments to be disabled as this is an open source application and StatsD isn&amp;#39;t required
  if Application.get_env(:instruments, :disabled) != true do
    {:ok, _} = Application.ensure_all_started(:instruments)
    interval = 1_000

    Instruments.Probe.define(
      &amp;quot;erlang.process_count&amp;quot;,
      :gauge,
      mfa: {:erlang, :system_info, [:process_count]},
      report_interval: interval
    )

    Instruments.Probe.define(
      &amp;quot;erlang.memory&amp;quot;,
      :gauge,
      mfa: {:erlang, :memory, []},
      keys: [:total, :atom, :processes],
      report_interval: interval
    )

    Instruments.Probe.define(
      &amp;quot;erlang.statistics.run_queue&amp;quot;,
      :gauge,
      mfa: {:erlang, :statistics, [:run_queue]},
      report_interval: interval
    )

    Instruments.Probe.define(
      &amp;quot;erlang.system_info.process_count&amp;quot;,
      :gauge,
      mfa: {:erlang, :system_info, [:process_count]},
      report_interval: interval
    )
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instruments&amp;rsquo; documentation discusses how custom probes can be designed for your application specifically. In addition to these probes, you can utilize Statix library to send StatsD metrics. That is outside of the scope of this post, but it is useful to note that Instruments defines &lt;a href="https://github.com/discordapp/instruments/blob/master/lib/instruments.ex#L78" target="_blank"&gt;various functions&lt;/a&gt; for sending data to the underlying Statix module. You can also use &lt;code&gt;Instruments.Statix&lt;/code&gt; directly, if that suits your needs better.&lt;/p&gt;

&lt;h1&gt;Final Thoughts&lt;/h1&gt;

&lt;p&gt;I haven&amp;rsquo;t seen any downside with Instruments yet that would make me use Elixometer again. It seems much easier to setup, is more obvious to read, and doesn&amp;rsquo;t involve interfacing with an erlang module in a sometimes confusing fashion. Due to all of this, it seems like a great package for setting up StatsD probes.&lt;/p&gt;

&lt;p&gt;I hinted at an open source implementation that uses Instruments. I&amp;rsquo;m working on putting the final touches on the repo and open-sourcing it under the SalesLoft Github org. There will be a blog post when that happens, as I&amp;rsquo;ve been trying to utilize best practices (of the current moment) when building it.&lt;/p&gt;
</content>
  </entry>
</feed>

<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Stephen Bussey's Software Engineering Blog</title>
  <id>https://stephenbussey.com</id>
  <link href="https://stephenbussey.com"/>
  <link href="https://stephenbussey.com/feed.xml" rel="self"/>
  <updated>2021-07-02T12:00:00-04:00</updated>
  <author>
    <name>Stephen Bussey</name>
  </author>
  <entry>
    <title>What is a GenServer?</title>
    <link rel="alternate" href="https://stephenbussey.com/2021/07/02/what-is-a-genserver.html"/>
    <id>https://stephenbussey.com/2021/07/02/what-is-a-genserver.html</id>
    <published>2021-07-02T12:00:00-04:00</published>
    <updated>2021-07-03T09:40:31-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;GenServer is one of the most common tools in the Elixir toolbag. I&amp;rsquo;ve &lt;a href="/2018/02/03/bringing-elixir-to-others-new-language-vs-new-paradigm.html" target="_blank"&gt;written in the past&lt;/a&gt; about why you don&amp;rsquo;t need to know about GenServers to get started with Elixir. However, you will inevitably hit the point where you want (or need) them. This post will be my description of a GenServer to beginners to the language.&lt;/p&gt;

&lt;h2&gt;Data is the foundation of programming&lt;/h2&gt;

&lt;p&gt;A seemingly simple question: what is programming? At the end of the day, most programming is assigning data to variables, operating on that data, moving it through different layers that apply other transformations, and then exposing it to some type of interface.&lt;/p&gt;

&lt;p&gt;Of course, we use libraries and frameworks for creating those interfaces (HTTP servers, Rails, Phoenix, etc.) although it&amp;rsquo;s turtles all the way down. We assign data to variables and operate on the variables.&lt;/p&gt;

&lt;p&gt;This takes us to the concept of an Object in object-oriented programming languages. An object combines (encapsulates) data and behavior. Encapsulation is good, because we can define what we want to do with our data (imposing limitations or processes around operations) with the thing that holds our data. For example, here&amp;rsquo;s a Ruby object that stores arbitrary data:&lt;/p&gt;

&lt;pre&gt;&lt;code class="ruby"&gt;class MyKeyStore
  def initialize
    @store = {}
  end

  def put(k, v)
    @store[k] = v
  end

  def get(k)
    @store[k]
  end
end

irb(main):046:0&amp;gt; store = MyKeyStore.new
=&amp;gt; #&amp;lt;MyKeyStore:0x0000000158209d20 @store={}&amp;gt;
irb(main):047:0&amp;gt; store.get(&amp;quot;a&amp;quot;)
=&amp;gt; nil
irb(main):048:0&amp;gt; store.put(&amp;quot;a&amp;quot;, &amp;quot;value&amp;quot;)
=&amp;gt; &amp;quot;value&amp;quot;
irb(main):049:0&amp;gt; store.get(&amp;quot;a&amp;quot;)
=&amp;gt; &amp;quot;value&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;ldquo;Okay, that&amp;rsquo;s Ruby. GenServers are Elixir.&amp;rdquo; Let&amp;rsquo;s look at how GenServers play into this.&lt;/p&gt;

&lt;h2&gt;GenServer Basics&lt;/h2&gt;

&lt;p&gt;A GenServer holds data and provides ways of interacting with that data. You can store any data you want in a GenServer (just like an Object in an OO language). You send messages to the GenServer&amp;rsquo;s process in order to interact with it. Ruby also uses message-passing to interact with objects, although is slightly different in practice.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s see our key-value object turned into a GenServer:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;defmodule MyKeyStore do
  def init([]) do
    # The map (%{}) here is our GenServer&amp;#39;s state, it could
    # be *anything* we want it to be
    {:ok, %{}}
  end

  def handle_call({:put, k, v}, _from, state) do
    next_state = Map.put(state, k, v)
    # We control the return value (2nd argument) and the next
    # state of our GenServer (3rd argument)
    {:reply, v, next_state}
  end

  def handle_call({:get, k}, _from, state) do
    {:reply, Map.get(state, k), state}
  end
end

iex(3)&amp;gt; {:ok, pid} = GenServer.start(MyKeyStore, [])
{:ok, #PID&amp;lt;0.129.0&amp;gt;}
iex(4)&amp;gt; GenServer.call(pid, {:get, &amp;quot;a&amp;quot;})
nil
iex(5)&amp;gt; GenServer.call(pid, {:put, &amp;quot;a&amp;quot;, &amp;quot;value&amp;quot;})
&amp;quot;value&amp;quot;
iex(6)&amp;gt; GenServer.call(pid, {:get, &amp;quot;a&amp;quot;})
&amp;quot;value&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;At its core, this is all that a GenServer is. It holds data and lets you define ways of interacting with that data. This particular example feels a lot like an Object, although it&amp;rsquo;s important to note that programming Elixir like an object-oriented language is not recommended.&lt;/p&gt;

&lt;p&gt;GenServers are capable of much more than this very basic example. This post isn&amp;rsquo;t serving to highlight what they can do, but just the basics of them. However, there&amp;rsquo;s one foundational element to GenServers that we absolutely need to talk about.&lt;/p&gt;

&lt;h2&gt;Data Lifecycle&lt;/h2&gt;

&lt;p&gt;Our programs are just data and operations on data, but there&amp;rsquo;s a crucial element that is missing: time. Every program that we write runs over a period of time. Often, we want to do things based on a certain frequency.&lt;/p&gt;

&lt;p&gt;The object in our Ruby example lacks the ability to deal with time. We would need to build that ourselves and deal with all of the challenges that would be introduced. However, we can easily create a GenServer that changes over time:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;defmodule ChangingNumber do
  def init([]) do
    send(self(), :change)
    # Our state this time is just a number, not a map like previous example
    {:ok, 0}
  end

  # handle_info is different than handle_call
  # No one is waiting for a response to this message, so we set the
  # new state and move on without replying.
  def handle_info(:change, _previous_number) do
    # Every 100ms, we will receive another change message
    Process.send_after(self(), :change, 100)
    next_number = :rand.uniform(9999)
    {:noreply, next_number}
  end

  def handle_call(:get, _from, number) do
    {:reply, number, number}
  end
end

iex(12)&amp;gt; {:ok, pid} = GenServer.start(ChangingNumber, [])
{:ok, #PID&amp;lt;0.156.0&amp;gt;}
iex(13)&amp;gt; GenServer.call(pid, :get)
4367
iex(14)&amp;gt; GenServer.call(pid, :get)
1357
iex(15)&amp;gt; GenServer.call(pid, :get)
8204
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this example, our &lt;code&gt;ChangingNumber&lt;/code&gt; GenServer process is actually sending a message &lt;em&gt;to itself in the future&lt;/em&gt;. Elixir&amp;rsquo;s runtime (the BEAM) dispatches this message to the process at the appropriate time.&lt;/p&gt;

&lt;p&gt;This is a very simple example, but the ability to control data over time is extremely powerful. We can build a key-value cache that clears out old keys to ensure our data footprint stays small. We can continually refresh a piece of data from our database and keep that data in memory for quick access. Things that we would usually introduce a third-party dependency for, we can just do ourselves.&lt;/p&gt;

&lt;p&gt;When I&amp;rsquo;m working with GenServers, I often think of them as a living thing. They can change over time (in the constraints that I&amp;rsquo;ve coded for them). They can emit messages to other GenServers in my system. They can be entirely contained or very sociable. They can exist for the duration of a web request, a WebSocket connection, or even exist as long as my system is up. I find that thinking of them in this way lets me build things that would be considered complex, but are very intuitive to develop and reason about.&lt;/p&gt;

&lt;p&gt;Okay, last thing about GenServers. Let&amp;rsquo;s look at the concept of data independence.&lt;/p&gt;

&lt;h2&gt;Data Independence&lt;/h2&gt;

&lt;p&gt;If data is at the core of our systems, then data is important. We need to protect our data and make our data lifecycle easy to reason about for the engineers on our team.&lt;/p&gt;

&lt;p&gt;GenServers live in their own little (mostly) isolated worlds. The technical reason for this is that they don&amp;rsquo;t share the same stack, and errors in one won&amp;rsquo;t propagate into an unrelated GenServer. This means that when we are thinking about &lt;code&gt;MyKeyStore&lt;/code&gt;, we only need to think about it and how it exposes its data via messages. We don&amp;rsquo;t need to worry about how other pieces of the system might blow up and take our GenServer down.&lt;/p&gt;

&lt;p&gt;This independence is why we don&amp;rsquo;t really need to think about explicit multi-threading in the Elixir world. Every GenServer is independent from others, and so our programs will execute on all available CPU cores without us needing to do anything at all.&lt;/p&gt;

&lt;p&gt;For me, this is one of the big selling points of Elixir and GenServers. A good example of this is that I once wanted to have an in-memory cache (in Ruby) of a piece of data loaded on every request in order to prevent database access. It would have been a really hard problem for me to deal with at the time due to the lack of independence between the cache and the rest of the system. Sure, for some it might be easy to do, but I think that it&amp;rsquo;s significantly easier to reason about (and build) with an independent data lifecycle.&lt;/p&gt;

&lt;h2&gt;What we didn&amp;rsquo;t cover&lt;/h2&gt;

&lt;p&gt;There&amp;rsquo;s a lot of meaty and interesting topics that we looked at today. There&amp;rsquo;s even more stuff that we didn&amp;rsquo;t talk about. If you&amp;rsquo;re interested in learning more, here&amp;rsquo;s some topics you might want to look up. Maybe these will be covered in a part 2 of this post:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GenServers are processes, so what exactly is a process?&lt;/li&gt;
&lt;li&gt;Supervisors are just special types of processes, effectively a special type of GenServer&lt;/li&gt;
&lt;li&gt;&lt;a href="/2018/01/08/designing-elixir-supervisor-trees.html" target="_blank"&gt;Designing supervision trees&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GenServers execute their messages sequentially, what&amp;rsquo;s the implication of this?&lt;/li&gt;
&lt;li&gt;&lt;a href="https://stackoverflow.com/questions/57380096/what-is-the-maximum-number-of-child-processes-a-supervisor-can-supervise" target="_blank"&gt;Is there a limit to the number of GenServers a system can have?&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2&gt;Thanks&lt;/h2&gt;

&lt;p&gt;Thanks to &lt;a href="https://www.mitchellhanberg.com" target="_blank"&gt;Mitch Hanberg&lt;/a&gt;, &lt;a href="https://keathley.io/" target="_blank"&gt;Chris Keathley&lt;/a&gt;, and Jess for reviewing this post and helping me clarify a few things.&lt;/p&gt;

&lt;h2&gt;The Book Plug&lt;/h2&gt;

&lt;p&gt;My book &amp;ldquo;Real-Time Phoenix: Build Highly Scalable Systems with Channels&amp;rdquo; is available at &lt;a href="https://bit.ly/rtp-gs-1" target="_blank"&gt;The Pragmatic Bookshelf&lt;/a&gt;. This book explores using Phoenix Channels, GenStage, and more to build
real-time applications in Elixir.&lt;/p&gt;

&lt;p&gt;I worked really hard to keep the material friendly to people that are new to Elixir and relevant for experienced Elixirists.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;a href="https://bit.ly/rtp-gs-1" target="_blank"&gt;
    &lt;img src="/images/sbsockets.jpg" alt="Real-Time Phoenix by The Pragmatic Bookshelf" height="300px" style="border: 1px solid #ccc" /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</content>
  </entry>
  <entry>
    <title>On Culture: Ending 7 Years at SalesLoft</title>
    <link rel="alternate" href="https://stephenbussey.com/2021/04/23/on-culture-ending-7-years-at-salesloft.html"/>
    <id>https://stephenbussey.com/2021/04/23/on-culture-ending-7-years-at-salesloft.html</id>
    <published>2021-04-23T16:00:00-04:00</published>
    <updated>2021-05-13T16:49:21-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;Today is my final day at SalesLoft. I&amp;rsquo;m moving to a full-time focus on Clove, which has pivoted into a much better product since my first post on it. I have some thoughts on writing about the technology powering Clove. We&amp;rsquo;re doing a lot of—I think—interesting things with Elixir to build a really great product.&lt;/p&gt;

&lt;p&gt;This post isn&amp;rsquo;t about that, though. I was reflecting on the most important thing that I learned at SalesLoft. What helped me grow the most? What kept me there for 7 years—an eternity in startup land? The answer is culture. I know, I know. Some people really don&amp;rsquo;t like that word, but let&amp;rsquo;s talk about it.&lt;/p&gt;

&lt;h2&gt;Early Company&lt;/h2&gt;

&lt;p&gt;The importance of culture was present from the very first conversation that I had with Rob, Kyle, and Tim—the founding team. They made clear that culture is not about tangible benefits you get from a company, but rather it&amp;rsquo;s about the shared set of values that the team is founded around. Values are the things that are never intentionally compromised on. If there&amp;rsquo;s a tough decision to make or challenge to tackle, the values must the center point of the thought-process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How are the core values of an early team established?&lt;/strong&gt; It&amp;rsquo;s going to be based around the founders. In the case of SalesLoft the values were positive, supportive, and self-starting. This came from Pardot, which David Cummings (early SL investor) was the founder of.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How are the core values played out?&lt;/strong&gt; They really need to be embraced by the team early on. This involves making them a center of conversation in all-hands, calling people out (kindly) if they aren&amp;rsquo;t living them, and involving them in hiring decisions.&lt;/p&gt;

&lt;h2&gt;Middle Stages&lt;/h2&gt;

&lt;p&gt;As the company matures and increases hiring (let&amp;rsquo;s say 100 employees in), the feeling in the company changed as well. Corporate policies are being played out more. Interviews are happening more frequently and with more applicants.&lt;/p&gt;

&lt;p&gt;SalesLoft tripled down on values during this period. It was great having focused discussions about the values, what they mean, and how they can help us interact better as a team. In particular, conflict resolution and how to directly face issues rather than triangulating were effective in helping to reenforce the values. I really looked forward to monthly all-hands breakfast where content about improving team health was presented.&lt;/p&gt;

&lt;p&gt;Trust was very much at the foundation of everything that we did. If you lookup the &amp;ldquo;5 functions of a team&amp;rdquo; model, you&amp;rsquo;ll see what I mean. One of the great quotes that always sticks with me is to &amp;ldquo;always assume positive intent&amp;rdquo; and &amp;ldquo;understand that you&amp;rsquo;re working towards the same outcome.&amp;rdquo; If a team member and I heavily disagreed about something, we could base ourselves around the outcome and realize that we&amp;rsquo;re reaching for the same thing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How might the core values of the team change?&lt;/strong&gt; I think minimal amount of change is a good thing in the foundational values (unless they were just bad and need redone). In SalesLoft&amp;rsquo;s case, aspirational values were added to the foundational values. Even to this day the original foundational values haven&amp;rsquo;t changed, although they moved from single words to phrases. The aspirational values were ultimately replaced again with two foundational ones.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How are the core values played out?&lt;/strong&gt; Team-building and trust are very important as teams are increasing in size. Communication becomes more difficult and fraught with misunderstandings. Values help the team center around the common foundation to solve problems. In addition, hiring has to evolve in this period of time. Hiring should involve focused culture-fit interviews that use a standardized path of questions and rubric. There should not be &amp;ldquo;gut feeling&amp;rdquo; in the hiring process, especially at this point.&lt;/p&gt;

&lt;h2&gt;Evolving into Enterprise&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m not sure if SalesLoft is at the point of counting as enterprise or not, although in my shoes 500 people was a lot compared to the original 10. At this point, hiring and employee churn start to become more visible. The percentage of churn doesn&amp;rsquo;t necessarily go up, but having 5x more employees means that the raw numbers will be 5x higher.&lt;/p&gt;

&lt;p&gt;As a company expands into departments the size of SMBs, values can really easily slip. I think it&amp;rsquo;s really important for the values to be lived and talked about both top-down and bottoms-up. The content around team-building and values is also important at this point, even more so than early days. SalesLoft had a great leadership course that people could take. It wasn&amp;rsquo;t a management course, to be clear, but discussed being a leader in role and values. I really enjoyed it.&lt;/p&gt;

&lt;p&gt;One exercise that stuck out to me, recently, was the co-founder Rob doing a clearing model exercise with one of his direct reports. She cleared an event that had bothered her the week before, in front of 500 people on zoom. The significance of this is that leaders need to be vulnerable, humble, and involved as the business grows. Otherwise, the values will slip.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How might the core values change?&lt;/strong&gt; I am not convinced that values changing at this point is a good thing. I have seen history of companies that go from a few effective values to way too many as the company gets larger. Values are not a means of control, and so keeping the foundation stable seems like a good idea. SalesLoft did not change the values so far in this stage, which I&amp;rsquo;m happy about.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;How are the core values played out?&lt;/strong&gt; Things will look pretty similar at this point, but I think it&amp;rsquo;s easier for microcosms to form where values might slip a little. Give awareness to everyone in the company about the values, what&amp;rsquo;s expected, and empower them to talk to their peers about issues.&lt;/p&gt;

&lt;p&gt;This is definitely the company stage where I have the least practical experience, though.&lt;/p&gt;

&lt;h2&gt;Future?&lt;/h2&gt;

&lt;p&gt;I am curious to see how SalesLoft will evolve its value system in the future. I won&amp;rsquo;t be along for the journey, but I hold a lot of confidence in the leadership team and the people that I interacted with on the daily.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m excited to take what I&amp;rsquo;ve seen and learned into my role as founder at Clove. We have a &lt;a href="https://cloveapp.io/about/" target="_blank"&gt;set of values&lt;/a&gt; at Clove, and they were based around our shared experience at SalesLoft.&lt;/p&gt;

&lt;p&gt;The most important thing to recognize about values is that no one is perfect. Things will slip, people will mess up now and then. There&amp;rsquo;s no shame in that. Recognize the importance of this as a learning opportunity, as it ultimately shapes how people apply core values in their daily actions.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>What's Next? Starting Clove</title>
    <link rel="alternate" href="https://stephenbussey.com/2020/08/30/what-s-next-starting-clove.html"/>
    <id>https://stephenbussey.com/2020/08/30/what-s-next-starting-clove.html</id>
    <published>2020-08-30T12:36:00-04:00</published>
    <updated>2021-05-13T16:49:21-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;In my previous post about writing Real-Time Phoenix, I questioned what&amp;rsquo;s next and mentioned that there were a few projects that I wanted to flesh out more. I&amp;rsquo;m really excited to announce that the main idea I&amp;rsquo;ve been bouncing around seems promising enough to build a start-up around it.&lt;/p&gt;

&lt;p&gt;My business partner, Andy, and I recently announced our work on &lt;a href="https://cloveapp.io/?utm_source=sb.com" target="_blank"&gt;Clove&lt;/a&gt;. In this post, I&amp;rsquo;m going to share the mission behind Clove, what our tech stack is like, and what is next for us.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/clove/li-banner.jpeg" alt="Clove Banner" /&gt;
&lt;/div&gt;

&lt;h2&gt;Our Mission with Clove&lt;/h2&gt;

&lt;p&gt;Clove is built around the idea that tech companies want to build a positive customer experience, but they struggle with building that experience between customers and support. Think about emailing the support department of a tool that you use&amp;mdash;are you filled with dread at the process, or excited to get a quick resolution to your problem? We want to make customers excited to get their problem fixed, quickly and easily.&lt;/p&gt;

&lt;p&gt;Our first product is an Intelligent Screen Recorder. Users record their screen and we capture all of the network requests, console logs, and performance data associated with that recording. This allows a support team to get all of the relevant information that they&amp;rsquo;d need to triage and potentially identify root-cause of a problem, without the customer needing to get on a screen share to figure out how to capture all of this data.&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re going to expand further into the interface between support and their customers. We have some other ideas that we&amp;rsquo;re mulling on, but we are looking to do more customer discovery to identify what&amp;rsquo;s best. If you are interested in sharing your perspective, please reach out!&lt;/p&gt;

&lt;h2&gt;Clove&amp;rsquo;s Tech Stack&lt;/h2&gt;

&lt;p&gt;The core of Clove is our Chrome extension that enables end-users to quickly record their screen. The extension is written completely in TypeScript, and the UI is built with React and Material UI.&lt;/p&gt;

&lt;p&gt;The most useful part of the extension architecture is a redux store that is driven by &lt;a href="https://github.com/tshaddix/webext-redux" target="_blank"&gt;webext-redux&lt;/a&gt;. This library lets you keep all of your data in the background page, and then the frontend views are automatically synchronized with that state. With this library, we are able to store all of the complex recording information in the background page, which we expose as a UI that is written with plain ol&amp;rsquo; React and Redux. We have a few UIs that are based on this state, such as the extension popup and the recording upload page.&lt;/p&gt;

&lt;p&gt;Clove&amp;rsquo;s backend is an Elixir monolith (that we intend to keep as such as we grow). Absinthe is used to provide a GQL API to the extension, but the bulk of the backend is powered by Phoenix LiveView. LiveView has been really great to work with, and has interfaced well with &lt;a href="https://github.com/material-components/material-components-web" target="_blank"&gt;Material Components Web&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;My favorite part of this stack is the re-use we get between the extension and the LiveView UI. We have a fairly complex React page that displays all of the diagnostic information for that recording session. This code is included in the LiveView app with about 15 lines of TypeScript and a git submodule. Complete code re-use without any hassle.&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s an example of the Chrome Extension version next to the in-app version. For the in-app version, the comments, page routing, and layout is all handled by LiveView.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/clove/clove-extension-network.png" alt="Clove's interface displaying a screen recording and network panel" /&gt;
&lt;/div&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/clove/clove-in-app.png" alt="Clove's in-app view demonstrating code re-use with the extension view" /&gt;
&lt;/div&gt;

&lt;h2&gt;What&amp;rsquo;s Next for Clove?&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;re working on getting off the ground with our initial product offering. We are bootstrapping (no VC $), so we&amp;rsquo;re very aware of the importance of a meaningful product offering that generates revenue. Once we have a few customers, we are going to expand further into the support space to develop a tighter product market fit.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m sure I&amp;rsquo;ll write a few more blog posts about what the tech is like at Clove. I think it&amp;rsquo;s actually very exciting and has been a very effective tech stack so far. I could see posts digging deeper into Chrome Extension APIs, starting a company through Stripe Atlas, the cross-context Redux pattern, or the LiveView&amp;lt;-&amp;gt;React code re-use that we have. Reach out on Twitter if anything sounds interesting to read about.&lt;/p&gt;

&lt;h2&gt;The Book Plug&lt;/h2&gt;

&lt;p&gt;My book &amp;ldquo;Real-Time Phoenix: Build Highly Scalable Systems with Channels&amp;rdquo; is available
through &lt;a href="http://bit.ly/rtp-clove" target="_blank"&gt;The Pragmatic Bookshelf&lt;/a&gt;. This book explores using Phoenix Channels, GenStage, and more to build real-time applications in Elixir.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;a href="http://bit.ly/rtp-clove" target="_blank"&gt;
    &lt;img src="/images/sbsockets.jpg" alt="Real-Time Phoenix by The Pragmatic Bookshelf" height="300px" style="border: 1px solid #ccc" /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</content>
  </entry>
  <entry>
    <title>My Experiences Writing Real-Time Phoenix</title>
    <link rel="alternate" href="https://stephenbussey.com/2020/05/06/my-experiences-writing-real-time-phoenix.html"/>
    <id>https://stephenbussey.com/2020/05/06/my-experiences-writing-real-time-phoenix.html</id>
    <published>2020-05-06T17:21:00-04:00</published>
    <updated>2021-05-13T16:49:21-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;The initial itch to write a book formed over a couple of weeks around October of 2018. Of course, I was very naïve at the time. I thought that a book could be written in three weeks if one simply battened down the hatches and got it done&amp;mdash;surely it would be done by Christmas. This may be true for some people, but the reality for me was quite different. This post goes through many of the different aspects of my writing journey.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m sure that everyone has a very different journey when writing a book, so take mine with a grain of salt. I&amp;rsquo;m hoping that you will find it useful if you&amp;rsquo;re thinking about writing, or maybe this post will help plant that seed. Maybe you&amp;rsquo;re just curious at the process of writing.&lt;/p&gt;

&lt;p&gt;This post will be a bit longer than usual as I want to make sure that the different aspects are explained in-depth.&lt;/p&gt;

&lt;p&gt;There is a 50% off code at the end of this post that is good until May 17, 2020. It&amp;rsquo;s the best deal you&amp;rsquo;re going to find!&lt;/p&gt;

&lt;h2&gt;Why I Decided to Write&lt;/h2&gt;

&lt;p&gt;I was working on a project to extract the &amp;ldquo;live feed&amp;rdquo; feature out of the SalesLoft Rails monolith. The actual API surface and moving parts are very simple, so this was a good candidate for a rewrite into a Phoenix-backed application. I spent a couple of weeks on the implementation and things were going well—it was time to roll it out.&lt;/p&gt;

&lt;p&gt;Despite the initial speed of developing the application, the rollout process took about 5 months. This was due to all of the little things that I took for granted coming to light. To be clear, the issues I ran into were not things that Phoenix lacked. Instead, they were the little nuances of writing a real-time app that I just didn&amp;rsquo;t know about. For example, I brought down the main application at least twice by overwhelming the monolith with thousands of simultaneous requests from the Elixir backend. (If you read the book, this is an example of an unintentional data pipeline, from Chapter 6.)&lt;/p&gt;

&lt;p&gt;I emerged from that project with a lot more Elixir knowledge and a good primer for how to write real-time apps. I was pretty convinced that my experiences on the project would be good to share with the world. I wrote some blog posts about it and got good reception on those, but I kept seeing people running into similar issues on Slack and the Forums. This cemented the idea as a good one for writing about. After writing a few more real-time features for SalesLoft, I knew it would be a good time to write.&lt;/p&gt;

&lt;h2&gt;Time to Find a Publisher&lt;/h2&gt;

&lt;p&gt;It seems that there are only a few major publishers in the Elixir world. The most prominent ones are Pragmatic Bookshelf and Manning Publications. Each publisher has an ideas email where you can shoot them an idea and they&amp;rsquo;ll let you know if they want a formal proposal or not. I submitted first to Pragmatic and&amp;hellip;the results were bad. I tried a few more times with them but I just couldn&amp;rsquo;t make it work. However, my call with Manning seemed to go well and I sent them a formal proposal.&lt;/p&gt;

&lt;p&gt;Writing a proposal is hard work. It was really the first dive into the book&amp;rsquo;s content that I took. I wrote pretty extensive outlines (I think something like 12 pages of just outlining) and had great feedback from the ten reviewers. The process of doing the proposal was one of the most valuable early stage things that I did though, because it forced me to flesh out my idea more and to realize what would and would not work. Despite the good feedback from Manning, I still really wanted to try to get something going with Pragmatic.&lt;/p&gt;

&lt;p&gt;I ran into Bruce Tate at Lonestar Elixir 2019. I asked him about writing and explained where I was at in the process with Manning. He gave me some great advice on how to tweak my initial proposal that I sent to Pragmatic:&lt;/p&gt;

&lt;p&gt;&lt;i&gt;&lt;strong&gt;Focus on what you can do with the technology, and less on the technology itself.&lt;/strong&gt;&lt;/i&gt;&lt;/p&gt;

&lt;p&gt;My initial proposal was all about WebSocket and writing apps with them. This was a bad proposal. He got me to flip this a bit into building scalable real-time systems (the final product vs the technology used).&lt;/p&gt;

&lt;p&gt;The new short-form proposal was well-received by the team. I was asked to send a formal proposal, which involves writing a meaty chapter from the book. This ended up being thirty pages of content. They reviewed this and it was accepted! I was going to write with Pragmatic! I was actually on the ski chairlift with my dad when the call from Bruce came in about it. I was so happy that I&amp;rsquo;m pretty sure I cried a bit.&lt;/p&gt;

&lt;p&gt;The process between Lonestar Elixir to a signed contract was only about three weeks. I was incredibly impressed by Pragmatic&amp;rsquo;s speed here, and knew it would be a sign of a good relationship.&lt;/p&gt;

&lt;h2&gt;The First Few Weeks&lt;/h2&gt;

&lt;p&gt;I was sent credentials to the Pragmatic build system, my book&amp;rsquo;s repository, a guide on how to write in their style (written using the same formatting as their books of course), and an introduction to my editor—Jackie. Everything came together quickly, so this felt very surreal and I wasn&amp;rsquo;t sure where to start.&lt;/p&gt;

&lt;p&gt;They coached through the beginning of the writing process. I put together a more built-out outline for every chapter and stubbed out chapters with some basic flow information. The initial ask was to put together chapters 2-4, with a sync up on style and writing after each. I buckled down and got to writing. I was given a bit of guidance (and had the writing style guide), but was told to predominately just stay in my own style for these initial chapters.&lt;/p&gt;

&lt;p&gt;The first chapters were difficult to write, to say the least. More difficult, however, was going through the chapters with Jackie and figuring out how to make them better. Each chapter would receive about fifty comments, so there was a lot to deal with. Like a PR, it is difficult to sent multiple weeks worth of work to someone else and have it broken down line by line. To anyone that hits this wall, it&amp;rsquo;s tough to deal with. Just keep learning, taking notes, adjusting, and pressing forward.&lt;/p&gt;

&lt;p&gt;One humorous anecdote during the initial weeks is that I sent Jackie an initial timeline which had me finished with the book in August, only a few months out. She let me know that this was quite ambitious and to basically double or triple that estimate to get to the final book. Engineers are always under or over estimating, it seems.&lt;/p&gt;

&lt;h2&gt;The Form of a Technical Book&lt;/h2&gt;

&lt;p&gt;One of the things that I hear most often when discussing writing a book is, &amp;ldquo;I could never do that, I can&amp;rsquo;t write 6 pages let alone 25, then 10+ chapters!&amp;rdquo; It is true that books are long and take time, but there&amp;rsquo;s a formula that honestly really helps out with the writing process.&lt;/p&gt;

&lt;p&gt;Every single one of my chapters, without fail, started with a basic outline that went 2 levels deep. The top heading would be the section&amp;rsquo;s title in the table of contents, and subheadings would be solely for breaking down content for the reader. Establishing this outline in a single sitting let me really clearly construct where I wanted the chapter to go, without anything context switching me away from it. I would note things that I wanted to especially hit on, as well. Once the outline was written, I would walk away from writing for the day.&lt;/p&gt;

&lt;p&gt;Each time that I sat down to write, I would start by establishing which of the subsections I wanted to write before calling it for the day. This gave me a goal that I could push for. To be honest, I wasn&amp;rsquo;t super great at hitting this all of the time, which I&amp;rsquo;ll touch on in the next section. I would try to complete a subheading in a single sitting to ensure continuity in my thoughts.&lt;/p&gt;

&lt;p&gt;When writing a subheading, it follows a pretty predictable formula again and again. There is an introduction paragraph that goes into what the section will be about. This sets the expectations for the reader. There are then 3-5 meaty paragraphs going over the content of the section. Sometimes the section would get broken down into another level of headings, if it was an especially meaty one. There is then a final paragraph that sets the reader up for the next section they&amp;rsquo;re going to read.&lt;/p&gt;

&lt;p&gt;This formula repeats for every section and every chapter of the entire book. I think that writing this way really helped me push through any mental barriers, and it also gives the reader knowledge of what they&amp;rsquo;re going to learn in the chapter and the sections of the chapter.&lt;/p&gt;

&lt;p&gt;A chapter follows this same formula. There is an introduction section of roughly four paragraphs. This is followed by the various sections (as mentioned above), and then a &amp;ldquo;Wrapping Up&amp;rdquo; section that closes out the chapter, and more importantly preps the reader for the next chapter. When you write this way, all of a sudden hitting 20+ pages per chapter doesn&amp;rsquo;t seem so bad.&lt;/p&gt;

&lt;h2&gt;The Long Haul&lt;/h2&gt;

&lt;p&gt;I was getting a pretty good rhythm going. Jackie was pleased with my writing, ability to quickly address feedback, and to reduce the number of repeat mistakes I would make. The number of times that I would get a chapter back from review, and the number of comments in the review, started to drop for each chapter. At the beginning, it would take at least three review rounds with 50, 35, 10 comments or so. By the end, it would take maybe two review rounds of 20, 5 comments.&lt;/p&gt;

&lt;p&gt;However, I also hit a pretty big mental wall. I made good progress on Part 1 of the book (6 chapters), and started on Part 2. Part 2 was so much harder because the project that we make in the book continues for the rest of the book. It turns out that writing a coherent and useful example that spans many chapters is really hard. I went from giving Jackie a chapter every two weeks to about one every four weeks. That wasn&amp;rsquo;t good.&lt;/p&gt;

&lt;p&gt;Writing during this time would often involve me sitting down at my computer and either doing nothing or doing very little for two hours. I felt pretty defeated, but I just couldn&amp;rsquo;t get it going. Another thing that I noticed is that I had a really hard time starting a new chapter, but I would push through a chapter pretty quickly once I started it. This is all pretty synonymous with burnout, which I&amp;rsquo;m sure there was a bit of.&lt;/p&gt;

&lt;p&gt;The thing that saved me the most during this time was ElixirConf 2019. I was doing a training on real-time application development there, and I wanted to have the book in a beta release by then. A beta release is reserved for books that are ~60% done and have a good velocity to the finish. I pushed really hard to get the necessary chapters done for the beta release and was successful at it. Pragmatic really did me some favors during this time, though, as another author gave up their beta spot by two weeks to help make sure that mine hit the goal. I appreciated that a ton.&lt;/p&gt;

&lt;p&gt;This long haul definitely ties into the hardest thing, for me, that happened when writing.&lt;/p&gt;

&lt;h2&gt;The Hardest Part of Writing a Book&lt;/h2&gt;

&lt;p&gt;The hardest part of me writing this book was not the technical or writing aspect of it. Instead, it was the gnawing feeling that I should be writing. Hanging out with friends on the weekend? (You should really be writing right now.) Christmas party for work? (Don&amp;rsquo;t drink much, you need to hit that writing goal, and you took a different day off.) Cycling on my Tuesday night ride? (You need to get done early so you can get an hour of writing in.) Basically everything that I did came with this feeling in the back of my head. Even if I wasn&amp;rsquo;t planning on writing that night, it was still prevalent. I only didn&amp;rsquo;t feel this way when I had just completed a chapter and sent it to Jackie.&lt;/p&gt;

&lt;p&gt;I put this here mainly as a warning and for something to consider if you&amp;rsquo;re looking to write a book. I haven&amp;rsquo;t really talked to many other authors about this feeling, so I&amp;rsquo;m curious if you wrote a book and the same thing happened to you. I have never felt this experience when it came to coding or other work, so it was new for me.&lt;/p&gt;

&lt;h2&gt;Refactoring&lt;/h2&gt;

&lt;p&gt;I have typically not been great at refactoring my writing. I will proofread this post once and ship it. I think it&amp;rsquo;s important to not get bogged down in the little nuances, as the alternative can be paralyzing and make it difficult to deliver content. However, this is clearly not how a book works.&lt;/p&gt;

&lt;p&gt;The story I want to share here is about chapter 3, 4, and 5 of the book. Believe it or not, these chapters started life as a single chapter. It was quite the monster, coming in at nearly 45 pages. The sample chapter that I wrote is closest to these chapters, which is part of why it may have ended up this way.&lt;/p&gt;

&lt;p&gt;I worked hard with my editor to find all of the seams in the monster chapter to see how it could be broken apart. Doing this involves changing almost all of the transition text (introduction and transition paragraphs in the earlier described form) and also requires checking continuity. So it&amp;rsquo;s not a small thing. I was also able to expand more on the content in these chapters because they no longer were crammed in way too tight. I am proud of the final result of this work, though, as I&amp;rsquo;ve gotten compliments on the way that the material in these chapters is delivered.&lt;/p&gt;

&lt;p&gt;I felt this same satisfaction anytime that I removed content. Removing content from a book is great, as it usually means that the concept can be described more simply and more succinctly somewhere else. Or it means that the content wasn&amp;rsquo;t important and that the reader no longer has to deal with carrying it in their head.&lt;/p&gt;

&lt;p&gt;Jackie was great at helping me see opportunities for refactoring my chapters. It&amp;rsquo;s her job to deliver a well-flowing book, and she does a great job at coaching through that.&lt;/p&gt;

&lt;h2&gt;Shipping The Book&lt;/h2&gt;

&lt;p&gt;The first release of the book came in August 2019 with the Beta release. This was definitely a big success for me, as it gave me motivation to keep pushing forward and also vetted the content with errata submissions. The final version released in April and has been available on &lt;a href="https://www.amazon.com/gp/product/1680507192" target="_blank"&gt;Amazon&lt;/a&gt; and &lt;a href="https://pragprog.com/book/sbsockets/real-time-phoenix" target="_blank"&gt;Pragmatic Bookshelf&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m very happy with the final result. I&amp;rsquo;ve gotten some unsolicited praise from people that I&amp;rsquo;ve never met on the way that the book flows and the information presented in it. I think that there is always room for improvement, but it is important to be satisfied with a job well done.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/holding-book.jpg" alt="Steve Bussey holding Real-Time Phoenix" style="border: 1px solid #ccc" /&gt;
&lt;/div&gt;

&lt;h2&gt;Thanks&lt;/h2&gt;

&lt;p&gt;Many people helped make this book possible. In particular, a decent number of technical reviewers contributed to vetting the material and helping to reduce the number of errors. This book would not have been the same without their suggestions and reviews. A large thanks to each of you: Amos King, Ben Olive, Chris Keathley, Dan Dresselhaus, Grant Powell, Gábor László Hajba, Johanna Larsson, John Oxford, Ray Gesualdo, Stefan Turalski, and Ulisses H. F. de Almeida.&lt;/p&gt;

&lt;p&gt;I also want to thank the community and maintainers of libraries. Phoenix is amazing and brings me joy. Part of the reason for this is that it is so well-maintained by Chris McCord and others who contribute to it. Chris and others also contributed with their one-one conversations and forum posts.&lt;/p&gt;

&lt;h2&gt;What&amp;rsquo;s Next?&lt;/h2&gt;

&lt;p&gt;Who knows, especially right now. I&amp;rsquo;m hoping to be able to continue trainings and presentations around the content in the book at conferences and meetups once things get back to normal. While I enjoyed the experience, I can say for sure that I&amp;rsquo;m not writing another book for a little bit. :)&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m excited to get back into writing some greenfield software. I have a few ideas in my mind that I&amp;rsquo;m excited to flesh out more over the next few months.&lt;/p&gt;

&lt;h2&gt;A Discount for the Weekend&lt;/h2&gt;

&lt;p&gt;There is a discount that is active on Pragmatic right now. You can get the Real-Time Phoenix ebook for 50% off, which is insane. You will not get a better price for as long as I can anticipate.&lt;/p&gt;

&lt;p&gt;You can use the coupon code &lt;strong&gt;Frameworks2020&lt;/strong&gt; for 50% off. This expires on May 17, 2020, although I&amp;rsquo;m not sure at what time. Purchase the book on &lt;a href="https://pragprog.com/book/sbsockets/real-time-phoenix" target="_blank"&gt;Pragmatic Bookshelf&lt;/a&gt; with this coupon code to redeem your 50% off! You can see which other books are available for this deal in the &lt;a href="https://media.pragprog.com/newsletters/2020-05-11.html" target="_blank"&gt;Pragmatic Newsletter&lt;/a&gt;.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Verifying Queries with Ecto's prepare_query Callback</title>
    <link rel="alternate" href="https://stephenbussey.com/2019/12/30/verifying-queries-with-ecto-s-prepare-query.html"/>
    <id>https://stephenbussey.com/2019/12/30/verifying-queries-with-ecto-s-prepare-query.html</id>
    <published>2019-12-30T13:28:00-05:00</published>
    <updated>2021-05-13T16:49:21-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;You can use many different techniques to build and scale Software as a Service applications. One technique that is very popular is
to use a single database for multiple paying customers. This multi-tenant approach to SaaS works well for many people, but there are
a few dangers to look out for. The biggest danger is the risk of cross-tenant data leaking. I consider this the worst possible scenario
for a multi-tenant SaaS application, even beyond a full system outage.&lt;/p&gt;

&lt;p&gt;In this post, we&amp;rsquo;re going to look at a technique to guarantee that cross-tenant leaks don&amp;rsquo;t happen in an Elixir application. We&amp;rsquo;ll be
looking at Ecto&amp;rsquo;s new(ish) &lt;code&gt;prepare_query&lt;/code&gt; callback and how it can be used to inspect (almost) every query that goes through your
application. I&amp;rsquo;ll discuss how I test drove a query inspector to inspect every query for tenancy.&lt;/p&gt;

&lt;p&gt;The ultimate goal of this post is to serve as a light reference for how I navigated the &lt;code&gt;Ecto.Query&lt;/code&gt; struct to implement
the tenancy enforcer. The biggest challenge that I faced was understanding what went into the structure and how to walk it.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s first look at what &lt;code&gt;prepare_query&lt;/code&gt; is.&lt;/p&gt;

&lt;h2&gt;Ecto&amp;rsquo;s &lt;code&gt;prepare_query&lt;/code&gt; Callback&lt;/h2&gt;

&lt;p&gt;The &lt;a href="https://hexdocs.pm/ecto/Ecto.Repo.html#c:prepare_query/3" target="_blank"&gt;&lt;code&gt;prepare_query&lt;/code&gt;&lt;/a&gt; callback was introduced in September of 2019. You
can define a function (&lt;code&gt;prepare_query&lt;/code&gt;) in your &lt;code&gt;Application.Repo&lt;/code&gt; module. The function is invoked before a query is executed, and you
are provided the full query structure as well as some metadata.&lt;/p&gt;

&lt;p&gt;With &lt;code&gt;prepare_query&lt;/code&gt;, you can inspect the query or even modify it. The Ecto documentation gives an example where a Repo filters out
&amp;ldquo;soft deleted&amp;rdquo; records unless the user is an admin. It looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;# From https://hexdocs.pm/ecto/Ecto.Repo.html#c:prepare_query/3

@impl true
def prepare_query(_operation, query, opts) do
  if opts[:admin] do
    {query, opts}
  else
    query = from(x in query, where: is_nil(x.deleted_at))
    {query, opts}
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can use this to detect whether a query has tenancy set correctly. We won&amp;rsquo;t actually modify the query in this post, due to
concerns I have with how that approach removes multi-tenancy awareness.&lt;/p&gt;

&lt;p&gt;In order to get started, we&amp;rsquo;ll need to define a function that shows us the &lt;code&gt;Ecto.Query&lt;/code&gt; structure. Let&amp;rsquo;s do that next.&lt;/p&gt;

&lt;h2&gt;Understanding Ecto Query Structure from Inspect Protocol&lt;/h2&gt;

&lt;p&gt;In order to get started with a runnable example, I modified
&lt;a href="https://github.com/sb8244/ecto_tenancy_enforcer/blob/master/test/support/tenancy/repo.ex" target="_blank"&gt;&lt;code&gt;test/support/tenancy/repo.ex&lt;/code&gt;&lt;/a&gt;
by replacing &lt;code&gt;prepare_query&lt;/code&gt; with the following empty function.&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;  def prepare_query(_operation, query, opts) do
    IO.inspect query
    {query, opts}
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I can then run the test &lt;code&gt;&amp;quot;valid tenancy is only condition&amp;quot;&lt;/code&gt; with &lt;code&gt;mix test test/integration/prepare_test.exs:26&lt;/code&gt;, and see the following
output:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;➜  ecto_tenancy_enforcer git:(master) ✗ mix test test/integration/prepare_test.exs:26
#Ecto.Query&amp;lt;from s0 in &amp;quot;schema_migrations&amp;quot;, lock: &amp;quot;FOR UPDATE&amp;quot;,
 select: type(s0.version, :integer)&amp;gt;
Including tags: [line: &amp;quot;26&amp;quot;]
Excluding tags: [:test]

#Ecto.Query&amp;lt;from c0 in Tenancy.Company, where: c0.tenant_id == 1, select: c0&amp;gt;
.

Finished in 0.2 seconds
43 tests, 0 failures, 42 excluded
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That&amp;rsquo;s not quite helpful, because the &lt;code&gt;Ecto.Query&lt;/code&gt; is printed out in text form. We can add &lt;code&gt;structs: false&lt;/code&gt; to the &lt;code&gt;IO.inspect&lt;/code&gt; call
and we get a different result.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;%{
  __struct__: Ecto.Query,
  aliases: %{},
  assocs: [],
  combinations: [],
  distinct: nil,
  from: %{
    __struct__: Ecto.Query.FromExpr,
    as: nil,
    hints: [],
    prefix: nil,
    source: {&amp;quot;companies&amp;quot;, Tenancy.Company}
  },
  group_bys: [],
  havings: [],
  joins: [],
  limit: nil,
  lock: nil,
  offset: nil,
  order_bys: [],
  prefix: nil,
  preloads: [],
  select: %{
    __struct__: Ecto.Query.SelectExpr,
    expr: {:&amp;amp;, [], [0]},
    fields: nil,
    file: &amp;quot;/Users/stephenbussey/src/ecto_tenancy_enforcer/deps/ecto/lib/ecto/query/planner.ex&amp;quot;,
    line: 814,
    params: [],
    take: %{}
  },
  sources: nil,
  updates: [],
  wheres: [
    %{
      __struct__: Ecto.Query.BooleanExpr,
      expr: {:==, [],
       [
         {{:., [], [{:&amp;amp;, [], [0]}, :tenant_id]}, [], []},
         %{
           __struct__: Ecto.Query.Tagged,
           tag: nil,
           type: {0, :tenant_id},
           value: 1
         }
       ]},
      file: &amp;quot;/Users/stephenbussey/src/ecto_tenancy_enforcer/test/integration/prepare_test.exs&amp;quot;,
      line: 27,
      op: :and,
      params: []
    }
  ],
  windows: [],
  with_ctes: nil
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alright, now we have the actual struct that we can work with. We are capable of writing a query, inspecting the struct, and then figuring
out how to walk / enforce that query. If we continued with TDD at this point, we&amp;rsquo;d eventually hit a snag. &lt;code&gt;Ecto.Query&lt;/code&gt; represents
referenced tables (joins, some wheres) with a positional index system. However, the structure doesn&amp;rsquo;t include
the list of positional references&amp;mdash;you have to build it yourself.&lt;/p&gt;

&lt;p&gt;This led to a bit of a pickle, because it&amp;rsquo;s not documented anywhere and is considered an internal query structure. However, we know
of at least one place that knows how to resolve a positional index into a table / module name (Ecto.Query inspect). Let&amp;rsquo;s find that
and see what it&amp;rsquo;s doing.&lt;/p&gt;

&lt;p&gt;A search for &lt;code&gt;defimpl&lt;/code&gt; in Ecto brings us to &lt;a href="https://github.com/elixir-ecto/ecto/blob/b3ee240e91deecfd6d8727946bfc8ed5de752e4f/lib/ecto/query/inspect.ex#L21" target="_blank"&gt;this line&lt;/a&gt;,
which is the implementation of &lt;code&gt;Inspect&lt;/code&gt; for &lt;code&gt;Ecto.Query&lt;/code&gt;. In particular, the following code is of interest to us:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;  defp to_list(query) do
    names =
      query
      |&amp;gt; collect_sources
      |&amp;gt; generate_letters
      |&amp;gt; generate_names
      |&amp;gt; List.to_tuple()

    ...
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With this lead, it&amp;rsquo;s possible to use these same functions to create a positional index lookup. You can see a finished example of this
in &lt;a href="https://github.com/sb8244/ecto_tenancy_enforcer/blob/master/lib/ecto_tenancy_enforcer/source_collector.ex" target="_blank"&gt;&lt;code&gt;EctoTenancyEnforcer.SourceCollector&lt;/code&gt;&lt;/a&gt;. I modified this to return the schema module name, rather than a letter or table name, so that I could use my
&lt;code&gt;enforced_schemas&lt;/code&gt; option to check if a referenced table needs checked or not.&lt;/p&gt;

&lt;p&gt;We have about as much as we&amp;rsquo;re going to get out of Ecto. At this point, it&amp;rsquo;s possible to jump in and start coding a query verifier to
do whatever you want. I found myself still a bit lost at this point, but I did know what I wanted to pass / fail. I&amp;rsquo;ll walk through
the steps I took to test drive a query enforcer.&lt;/p&gt;

&lt;h2&gt;Test Driving EctoTenancyEnforcer&lt;/h2&gt;

&lt;p&gt;I don&amp;rsquo;t practice test driven development often, but I find it valuable when I have no clue what the solution is going to be, but I
know what I want it to look like. That is the case in a query enforcer, because it&amp;rsquo;s easy to write out queries that should pass and
fail into a test suite. I can then go one-by-one to make the incorrect ones fail, while still having the valid ones pass.&lt;/p&gt;

&lt;p&gt;I started with a set of very simple tests, like so:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;test &amp;quot;no filters at all&amp;quot; do
  assert_raise(TenancyViolation, fn -&amp;gt;
    Repo.all(Company)
  end)
end

test &amp;quot;valid tenancy is only condition&amp;quot; do
  valid = from c in Company, where: c.tenant_id == 1
  assert Repo.all(valid) |&amp;gt; length == 1
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I started with these to build some simple confidence. Once they were passing, I listed out about 40 queries that I knew should work
or not work. I chipped my way through these and eventually found the patterns in the &lt;code&gt;Ecto.Query&lt;/code&gt; struct that led to fairly clean code to
walk them.&lt;/p&gt;

&lt;p&gt;The final result can be seen in the &lt;a href="https://github.com/sb8244/ecto_tenancy_enforcer/blob/master/lib/ecto_tenancy_enforcer/query_verifier.ex" target="_blank"&gt;&lt;code&gt;EctoTenancyEnforcer.QueryVerifier&lt;/code&gt;&lt;/a&gt; module. I&amp;rsquo;m sure that there are cases I missed in my TDD, but I&amp;rsquo;m happy enough with this to
use it in production applications. I&amp;rsquo;ll add new tests as cases are encountered in the wild.&lt;/p&gt;

&lt;h2&gt;Wrapping Up&lt;/h2&gt;

&lt;p&gt;Ecto&amp;rsquo;s &lt;code&gt;prepare_query&lt;/code&gt; callback is incredibly powerful for query inspection and modification. It&amp;rsquo;s a bit dense to get started with,
due to the &lt;code&gt;Ecto.Query&lt;/code&gt; structure being undocumented, but TDD helped me out significantly. The &lt;code&gt;Ecto.Query&lt;/code&gt; walking is undocumented,
but I&amp;rsquo;m anticipating stability in the Query structure going into the future. That may or may not pan out, but I think it&amp;rsquo;s a decent
bet.&lt;/p&gt;

&lt;p&gt;If you&amp;rsquo;re looking for tenancy enforcement in Ecto queries, try out &lt;a href="https://github.com/sb8244/ecto_tenancy_enforcer" target="_blank"&gt;EctoTenancyEnforcer&lt;/a&gt;.
You can refer to this repo as a complete example of query enforcement.&lt;/p&gt;

&lt;h2&gt;The Book Plug&lt;/h2&gt;

&lt;p&gt;My book &amp;ldquo;Real-Time Phoenix: Build Highly Scalable Systems with Channels&amp;rdquo; is now in beta
through &lt;a href="http://bit.ly/rtp-exq" target="_blank"&gt;The Pragmatic Bookshelf&lt;/a&gt;. This book explores using Phoenix Channels, GenStage, and more to build
real-time applications in Elixir. The first draft has been completed for a little bit and the book should be in production by
February, with print coming at the end of the production process.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;a href="http://bit.ly/rtp-ecto-tenancy" target="_blank"&gt;
    &lt;img src="/images/sbsockets.jpg" alt="Real-Time Phoenix by The Pragmatic Bookshelf" height="300px" style="border: 1px solid #ccc" /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</content>
  </entry>
  <entry>
    <title>Improve Exq Writes With Pooling</title>
    <link rel="alternate" href="https://stephenbussey.com/2019/10/01/improve-exq-writes-with-pooling.html"/>
    <id>https://stephenbussey.com/2019/10/01/improve-exq-writes-with-pooling.html</id>
    <published>2019-10-01T00:26:00-04:00</published>
    <updated>2021-05-13T16:49:21-04:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;&lt;a href="https://hex.pm/packages/exq" target="_blank"&gt;Exq&lt;/a&gt; is a background job processing library written in Elixir. It uses Redis, via the
Redix library, to store and then retrieve jobs. In this post, we&amp;rsquo;ll look at the performance of writing jobs into Redis
via the &lt;code&gt;Exq.Enqueuer&lt;/code&gt; API. You&amp;rsquo;ll see several benchmarks that utilize a single &lt;code&gt;Enqueuer&lt;/code&gt;, a poolboy queue, and a named
process pool.&lt;/p&gt;

&lt;p&gt;The repo for the benchmark and sample application is at &lt;a href="https://github.com/sb8244/exq-throughput" target="_blank"&gt;https://github.com/sb8244/exq-throughput&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;The Problem&lt;/h2&gt;

&lt;p&gt;Background job processing libraries write their jobs into a persistent storage mechanism and then retrieve those jobs
in the future. If you&amp;rsquo;ve used Ruby, you may be familiar with Sidekiq. The act of writing to Redis is very fast, but there
can be overhead at multiple levels. If the overhead is too high, then writing jobs to Redis becomes slow and the application
may become backed up. This can lead to errors or even a loss of service, if acknowledged persistence of a job is required.&lt;/p&gt;

&lt;h2&gt;Types of Overhead&lt;/h2&gt;

&lt;p&gt;The most common overhead that I&amp;rsquo;ve seen is the backup of Redis commands being executed end-to-end serially. This happens
when you use a single connection to write to Redis, and can occur in any language. The issue arises because a single connection can only
send one command at a time. It must then wait for the response before another command can occur. Redis is single-threaded, so it may not
be obvious why this is an issue. The problem is that the network overhead is done serially in this type of system—each write has to
go over the network and back before the next starts.&lt;/p&gt;

&lt;p&gt;The following diagram shows the speed of three hypothetical Redis requests:&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/ExqPool/redis_serialization.svg"
       alt="Redis single connection versus pooled connection. Pooled connection completes 3 requests much faster."
       height="375px" /&gt;
  &lt;p&gt;
    &lt;small&gt;&lt;i&gt;Redis single connection versus pooled connection. Pooled connection completes 3 requests much faster.&lt;/i&gt;&lt;/small&gt;
  &lt;/p&gt;
&lt;/div&gt;

&lt;p&gt;Each connection sends a command that goes over the network to Redis, which processes the command. A response is returned
and also goes over the network. In the real-world, this network latency might be 1ms or less. However, the end result is that
the requests complete much faster when multiple commands can be simultaneously sent via multiple connections.&lt;/p&gt;

&lt;p&gt;Another type of overhead is the fact that an Elixir process handles messages serially. If a job is enqueued via a single
process, the same problem as a single connection emerges.&lt;/p&gt;

&lt;h2&gt;The Problem in Exq&lt;/h2&gt;

&lt;p&gt;Exq enqueues jobs through the &lt;code&gt;Exq.Enqueuer&lt;/code&gt; process. This is a single process that holds a single redis connection. Each enqueue
task goes through this one process, serially. If serial processes and single connections lead to less throughput, then this is
will limit the throughput of Exq enqueueing.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s move into what we can do about it, and then benchmarks.&lt;/p&gt;

&lt;h2&gt;Pool Processes to Increase Throughput&lt;/h2&gt;

&lt;p&gt;The solution to the problem above is to pool processes, so that multiple Redis commands can be sent to Redis in the same moment
of time. There are two main ways that I&amp;rsquo;ve done this in Elixir: poolboy and named pools.&lt;/p&gt;

&lt;h4&gt;Poolboy&lt;/h4&gt;

&lt;p&gt;&lt;a href="https://github.com/devinus/poolboy" target="_blank"&gt;Poolboy&lt;/a&gt; is a nifty Erlang library that can create a pool of any process you want. We could
pool &lt;code&gt;Exq.Enqueuer&lt;/code&gt; processes and then enqueue jobs by using the poolboy functions. Let&amp;rsquo;s see how we&amp;rsquo;d do that:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;defmodule ExqThroughput.Application do
  use Application

  def start(_type, _args) do
    children =
      [
        :poolboy.child_spec(:worker, poolboy_config())
      ]

    opts = [strategy: :one_for_one, name: ExqThroughput.Supervisor]
    Supervisor.start_link(children, opts)
  end

  def enqueuer_pool_size(), do: :erlang.system_info(:schedulers_online)

  def poolboy_config() do
    [
      {:name, {:local, :enqueuer}},
      {:worker_module, ExqThroughput.PooledEnqueuer},
      {:size, enqueuer_pool_size()}
    ]
  end
end

defmodule ExqThroughput.PooledEnqueuer do
  def start_link(_) do
    # Hack to make Exq happy with running
    num = :rand.uniform(100_000_000) + 100
    name = :&amp;quot;Elixir.Exq#{num}&amp;quot;
    Exq.Enqueuer.start_link(name: name)

    # We need to put the enqueuer instance into the pool
    {:ok, Process.whereis(:&amp;quot;#{name}.Enqueuer&amp;quot;)}
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is a bit of a hack in the &lt;code&gt;PooledEnqueuer&lt;/code&gt; module to make Exq happy. There may be another way to get around this, but I went
for a quick solution for the purpose of this benchmark. There is also a bit of working around the Exq process tree to get access
directly to the Enqueuer process.&lt;/p&gt;

&lt;p&gt;We can now enqueue a job by first checking out the poolboy process:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;:poolboy.transaction(:enqueuer, fn pid -&amp;gt;
  Exq.enqueue(pid, &amp;quot;throughput_queue&amp;quot;, Worker, [])
end)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Named process pooling looks a bit different than this.&lt;/p&gt;

&lt;h4&gt;Named Processes&lt;/h4&gt;

&lt;p&gt;You can start multiple processes in Elixir and give them a name like &lt;code&gt;MyProcess1&lt;/code&gt;, &lt;code&gt;MyProcess2&lt;/code&gt;, etc. When you want to send a
message to the process, you would send a message to &lt;code&gt;:&amp;quot;Elixir.MyProcess#{:rand.uniform(2)}&amp;quot;&lt;/code&gt;. This is named process pooling, and is
conceptually very simple—this makes it easier to setup.&lt;/p&gt;

&lt;p&gt;We have to start the pool of processes in the application:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;defmodule ExqThroughput.Application do
  use Application

  def start(_type, _args) do
    children = named_enqueuer_pool(enqueuer_pool_size())
    opts = [strategy: :one_for_one, name: ExqThroughput.Supervisor]
    Supervisor.start_link(children, opts)
  end

  def enqueuer_pool_size(), do: :erlang.system_info(:schedulers_online)

  defp named_enqueuer_pool(count) do
    for i &amp;lt;- 1..count do
      name = :&amp;quot;Elixir.Exq#{i}&amp;quot;

      %{
        id: name,
        start: {Exq.Enqueuer, :start_link, [[name: name]]}
      }
    end
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can then enqueue work by directly using these processes:&lt;/p&gt;

&lt;pre&gt;&lt;code class="elixir"&gt;def named_enqueue() do
  num = :rand.uniform(ExqThroughput.Application.enqueuer_pool_size())
  Exq.enqueue(:&amp;quot;Elixir.Exq#{num}.Enqueuer&amp;quot;, &amp;quot;throughput_queue&amp;quot;, Worker, [])
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I love this approach due to its simplicity. Let&amp;rsquo;s see how all of the approaches stack up.&lt;/p&gt;

&lt;h2&gt;Benchmark&lt;/h2&gt;

&lt;p&gt;Benchee is used to benchmark three scenarios: single process, poolboy, named processes. Benchee is ran with various
parallelism amounts to simulate how you might run Exq in production. For example, if you are enqueueing from a web tier,
then your parallelism will be quite high. If you&amp;rsquo;re enqueueing from a single process, you would have no parallelism.&lt;/p&gt;

&lt;p&gt;The redis queues are cleaned up before/after each test. The Exq work processor is not running—this test is purely around
speed of enqueueing. These tests are all running locally, and Redis is not running through any type of virtualization. The performance
would be significantly different depending on how redis is setup and the network speed between your application and redis.&lt;/p&gt;

&lt;p&gt;When Benchee was run with a single runner, all of the approaches came out roughly the same. This is expected because we
won&amp;rsquo;t see parallelism benefits without multiple processes trying to enqueue.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Name                       ips        average  deviation         median         99th %
named enqueuer          9.05 K      110.52 μs    ±42.61%          99 μs         210 μs
poolboy enqueuer        8.73 K      114.51 μs    ±57.05%         102 μs         240 μs
default enqueuer        8.30 K      120.54 μs    ±51.87%         110 μs         249 μs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The difference with 6 parallel testers was quite different. We can see that the pool approaches have significantly higher
throughput:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total ips is these numbers * 6
Name                       ips        average  deviation         median         99th %
poolboy enqueuer        4.40 K      227.14 μs    ±39.15%         216 μs         417 μs
named enqueuer          3.95 K      253.41 μs    ±45.96%         227 μs         605 μs
default enqueuer        1.05 K      954.02 μs    ±21.91%         951 μs     1446.13 μs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now for 12:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total ips is these numbers * 12
Name                       ips        average  deviation         median         99th %
poolboy enqueuer        2.83 K      352.86 μs    ±26.97%         339 μs         655 μs
named enqueuer          2.78 K      359.24 μs    ±53.25%         302 μs        1004 μs
default enqueuer        0.84 K     1187.04 μs    ±21.96%        1121 μs     1882.19 μs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and 24:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total ips is these numbers * 24
Name                       ips        average  deviation         median         99th %
named enqueuer          1.48 K      675.58 μs    ±66.26%      541.98 μs     2198.98 μs
poolboy enqueuer        1.06 K      942.92 μs    ±51.20%      845.98 μs     2470.98 μs
default enqueuer        0.34 K     2900.89 μs    ±19.05%     2765.98 μs     4482.25 μs
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;That one surprised me because the named enqueuer was significantly more performant. I tried it over 10 times and
consistently got the same results. The tests were run in different order each time.&lt;/p&gt;

&lt;p&gt;That disappeared for 48:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;total ips is these numbers * 48
Name                       ips        average  deviation         median         99th %
poolboy enqueuer        912.30        1.10 ms    ±30.56%        1.01 ms        2.35 ms
named enqueuer          896.40        1.12 ms    ±77.47%        0.86 ms        4.06 ms
default enqueuer        203.05        4.92 ms    ±18.66%        4.65 ms        8.84 ms
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Interpreting the Results&lt;/h2&gt;

&lt;p&gt;These results show, clearly, that pooling the &lt;code&gt;Exq.Enqueuer&lt;/code&gt; process significantly increases throughput. This might be
even more pronounced when Redis is accessed over the network.&lt;/p&gt;

&lt;p&gt;Each test increased the parallelism, and the gap between pooled and single got even larger. With 48 processes enqueueing jobs, the total
throughput per second is ~43,000 versus ~9,600. With 12 processes enqueueing jobs, the throughput per second is still ~33,000 versus
~10,000.&lt;/p&gt;

&lt;h2&gt;Action the Results&lt;/h2&gt;

&lt;p&gt;If you are using Exq in production, consider pooling the enqueuer processes to increase throughput capacity. You may also increase
your enqueue speeds even if you&amp;rsquo;re not at capacity. You can use any pooling approach you want, they are roughly the same and
have a substantial impact to throughput.&lt;/p&gt;

&lt;p&gt;Exq already has an open issue to discuss adding some type of parallelism to the enqueuer process. Thanks to my colleague Marco for
opening that issue and for letting me look at this problem with him.&lt;/p&gt;

&lt;h2&gt;The Book Plug&lt;/h2&gt;

&lt;p&gt;My book &amp;ldquo;Real-Time Phoenix: Build Highly Scalable Systems with Channels&amp;rdquo; is now in beta
through &lt;a href="http://bit.ly/rtp-exq" target="_blank"&gt;The Pragmatic Bookshelf&lt;/a&gt;. This book explores using Phoenix Channels, GenStage, and more to build
real-time applications in Elixir.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;a href="http://bit.ly/rtp-exq" target="_blank"&gt;
    &lt;img src="/images/sbsockets.jpg" alt="Real-Time Phoenix by The Pragmatic Bookshelf" height="300px" style="border: 1px solid #ccc" /&gt;
  &lt;/a&gt;
&lt;/div&gt;
</content>
  </entry>
</feed>

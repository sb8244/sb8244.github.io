<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Stephen Bussey's Software Engineering Blog</title>
  <id>https://stephenbussey.com</id>
  <link href="https://stephenbussey.com"/>
  <link href="https://stephenbussey.com/feed.xml" rel="self"/>
  <updated>2018-02-17T02:07:00-05:00</updated>
  <author>
    <name>Stephen Bussey</name>
  </author>
  <entry>
    <title>28 Days - pg2 basics - Use process groups for orchestration across a cluster</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/02/17/pg2-basics-use-process-groups-for-orchestration-across-a-cluster.html"/>
    <id>https://stephenbussey.com/2018/02/17/pg2-basics-use-process-groups-for-orchestration-across-a-cluster.html</id>
    <published>2018-02-17T02:07:00-05:00</published>
    <updated>2018-02-17T03:13:06-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;One of my first major Elixir projects really cared about optimization up-front,
due to high throughput. This led to my mentality of &amp;ldquo;no database&amp;rdquo;; I would try
to always keep data in local heap rather than going to a database. I quickly
encountered the biggest challenge with this: how to keep the processes that
hold data in sync with each other. I looked at using &lt;a href="http://erlang.org/doc/man/pg2.html" target="_blank"&gt;pg2&lt;/a&gt;
for this task, and have been very happy with the outcome.&lt;/p&gt;

&lt;p&gt;An example repo is up at &lt;a href="https://github.com/sb8244/pg2_demo" target="_blank"&gt;https://github.com/sb8244/pg2_demo&lt;/a&gt;.&lt;/p&gt;

&lt;h2&gt;pg2&lt;/h2&gt;

&lt;p&gt;&lt;a href="http://erlang.org/doc/man/pg2.html" target="_blank"&gt;pg2&lt;/a&gt; has nothing to do with postgres,
which is one of the most common thoughts when people see the module name.
It creates process groups, so that is where the name comes from.&lt;/p&gt;

&lt;p&gt;At the most basic explanation, pg2 allows for a group to be created and then
for processes to connect to the group. This leads to a mapping of name -&amp;gt; pid list.
The pid list consists of all known processes, whether they be local or remote.
When a pg2 group is created, that group becomes visible to all connected nodes
in the system. A pg2 group can be created multiple times without error, which
means that each node can call &lt;code&gt;create&lt;/code&gt; without error.&lt;/p&gt;

&lt;h2&gt;In practice&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;ll preface this by saying that my particular problem could be solved a number of
ways, this is just the way I approached it. Also, pg2 can be used many different ways.
If you see any better approach for either the problem or solution, please let me know!&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s walk through each section of a module found in the &lt;a href="https://github.com/sb8244/pg2_demo" target="_blank"&gt;demonstration repo&lt;/a&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;defmodule MyWorker.Synchronization do
  use GenServer

  # The topic could simply be __MODULE__, but I like having the human name in it as well
  @topic {:human_name, __MODULE__}

  def start_link do
    GenServer.start_link(__MODULE__, [])
  end

  def topic, do: @topic
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;pg2 works by grouping processes, so we need a process to group. I satisfy this by
creating a process specifically for synchronization purposes. It would be possible
to link this to the main process (MyWorker above), but there would be less performance
with the serial nature of a process.&lt;/p&gt;

&lt;p&gt;The topic is just a tuple or atom, (erlang typespec is &amp;ldquo;any&amp;rdquo;), and I generally like to
have some human readability in the topic.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  def init([]) do
    :ok = :pg2.create(@topic)
    :ok = :pg2.join(@topic, self())
    {:ok, []}
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the Synchronization GenServer starts, it is going to create the pg2 topic and
then join the topic itself. This is possible due to the property pointed out earlier
that &lt;code&gt;:pg2.create&lt;/code&gt; can be called multiple times successfully.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  def update(some_param) do
    :pg2.get_members(@topic)
    |&amp;gt; Kernel.--(:pg2.get_local_members(@topic))
    |&amp;gt; Enum.each(fn(pid) -&amp;gt;
      send pid, {:broadcast, @topic, {:update_from_db, some_param}}
    end)
  end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the public API of the Synchronization module. The process group&amp;rsquo;s members
are retrieved, which is every pid (local and remote) added to the group. In our case,
it is only Synchronization module pids. Local processes are removed from this list for
performance reasons. In my use case, the data on the local node is already correct;
the local node does not need updated.&lt;/p&gt;

&lt;p&gt;Each pid is then enumerated and is sent a broadcast message which can actually be
any atom or tuple that we like. This can be useful for passing around parameters
such as the changed data or tenant information.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  def handle_info({:broadcast, @topic, {:update_from_db, some_param}}, state) do
    MySupervisor.for_param(some_param)
      |&amp;gt; MyWorker.load_from_db()
    {:noreply, state}
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, the message we passed around is handled. In this short demo, I&amp;rsquo;m not worrying
about sending the changed messages over the wire, instead I am just loading it from the database.
This can be desirable for simplicity&amp;rsquo;s sake if the data isn&amp;rsquo;t changing often.&lt;/p&gt;

&lt;h2&gt;A note on distributing data&lt;/h2&gt;

&lt;p&gt;Keeping multiple copies of the same data in memory, and up to date, across an entire
cluster is a pretty hard problem, without going into details of &lt;a href="https://en.wikipedia.org/wiki/CAP_theorem" target="_blank"&gt;CAP theorem&lt;/a&gt;.
In this pg2 solution, the data is eventually consistent. This means that some servers
may give an incorrect answer over no answer, because they don&amp;rsquo;t have the most recent
data yet.&lt;/p&gt;

&lt;p&gt;More stringent handling of the &lt;code&gt;send&lt;/code&gt; could be coded if needed, although considering
distributed data from the beginning is worth it.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading the 16th post in my 28 days of Elixir. Keep up through the month of February to see if I can
stand subjecting myself to &lt;a href="/tags/28-days-of-elixir.html" target="_blank"&gt;28 days of straight writing&lt;/a&gt;. I
am looking for new topics to write about, so please reach out if there&amp;rsquo;s anything you
really want to see!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>28 Days - My favorite Elixir testing tool - Mockery</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/02/15/my-favorite-elixir-testing-tool-mockery.html"/>
    <id>https://stephenbussey.com/2018/02/15/my-favorite-elixir-testing-tool-mockery.html</id>
    <published>2018-02-15T18:23:00-05:00</published>
    <updated>2018-02-15T20:33:13-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;I hate to admit it, but I&amp;rsquo;ve finally started truly unit testing with Elixir. I come
from the Ruby world where our large test suite often runs slowly due to things like
data insertion / access in the tests, large object graphs, etc. It&amp;rsquo;s easy to criticize
situations like this after the fact, but I find the reasons along the way were paved
with the best intentions. As I learn and adopt Elixir at SalesLoft, I&amp;rsquo;ve been extra
careful to avoid these situations from playing out again.&lt;/p&gt;

&lt;p&gt;The biggest tool in my arsenal so far has been &lt;a href="https://github.com/appunite/mockery" target="_blank"&gt;Mockery&lt;/a&gt;, a mocking tool that
allows the test suite to be run in parallel. This seems like a natural thing to expect
from a mocking tool, but some others that I used do not have this property. I think
that the design of Mockery also leads to cleaner code, so I&amp;rsquo;ve adopted it.&lt;/p&gt;

&lt;h2&gt;Mockery Usage&lt;/h2&gt;

&lt;p&gt;The Github for Mockery lays out all different usage possibilities for it, I&amp;rsquo;ll just
cover the one or two that I use most often.&lt;/p&gt;

&lt;p&gt;The first, and most common case, is mocking out expensive operations. An example of this is network requests;
I&amp;rsquo;m able to use tools to test these requests (topic for another post?), in their specific modules,
but then keep these requests out of other places. Another example is for database access. I
can write query objects or repositories to handle the fetching / insertion of data, but
then mock out these modules in their usage throughout a system. Here&amp;rsquo;s an example usage:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;defmodule MyRequest do
  @widgets_query Mockery.of(&amp;quot;WidgetsQuery&amp;quot;)

  def call(authentication_context) do
    @widgets_query.call(authentication_context)
  end
end

defmodule MyRequestTest do
  use ExUnit.Case, async: true
  use Mockery

  test &amp;quot;call returns the widgets query&amp;quot; do
    auth = %{}
    mock WidgetsQuery, :call, [%Widget{id: 1}, %Widget{id: 2}]
    assert MyRequest.call(auth) == [%Widget{id: 1}, %Widget{id: 2}]
    assert_called WidgetsQuery, :call, [^auth]
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is about the most basic usage to Mockery possible. The module is mocked
for this process only, then used by the request. After the call, we can check that
it was called properly. This allows the important parts of a mock to be fully covered
in our test suite: params and results.&lt;/p&gt;

&lt;p&gt;There is another usage of Mockery that I&amp;rsquo;ve found useful, it&amp;rsquo;s to implement a mock that
always exists unless specified by a test. In the above mock example, if we wrote another
test, that module would not be mocked anymore, leading to a real database call. This
may not be desired if we end up mocking a module in a lot of places. Enter &lt;code&gt;by:&lt;/code&gt; keyword:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@widgets_query Mockery.of(&amp;quot;WidgetsQuery&amp;quot;, by: &amp;quot;WidgetsQuery.Mock&amp;quot;)

defmodule WidgetsQuery do
  defmodule Mock do
    def call(_auth), do: []
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the above usage of Mockery, any call in a normal test will return an empty list.
This may not be desirable for certain cases, so your mileage will vary with such a
technique.&lt;/p&gt;

&lt;h2&gt;Mockery for Processes&lt;/h2&gt;

&lt;p&gt;Another really powerful use case of mocking, that I&amp;rsquo;ve found and think warrants a
separate mention, is for process based communication. In practice, testing processes
can get a bit hairy. Timing, process ownership, race conditions are all easily possible
in tests due to tests running in a process and our code being able to run in processes.
Mockery can help out here by mocking out the explicit boundaries between processes.&lt;/p&gt;

&lt;p&gt;While I find a ton of power in Mockery for this use case, I urge even more caution than
others. It would be possible to devise an incorrect process tree that works in tests
solely because of mocking. Don&amp;rsquo;t shy away from mocking, but don&amp;rsquo;t take to it immediately
either.&lt;/p&gt;

&lt;h2&gt;Dangers of mocking&lt;/h2&gt;

&lt;p&gt;Mocking is not a silver bullet for tests. It can certainly help greatly with common
expensive operations and allows for testing of boundaries rather than going past
the boundaries in each test. However, what if our boundaries are not correct?&lt;/p&gt;

&lt;p&gt;A few common issues arise with mocking. It is possible to setup a mock on a function
that doesn&amp;rsquo;t exist, on params that are not reflective of reality, and on results that
are not part of the type signature of the function. Each of these scenarios has the
potential for a worst case testing scenario: code that passes locally but fails in
QA or production testing.&lt;/p&gt;

&lt;p&gt;Mockery does help with the function not existing, as it requires mocking out functions
that do exist in the target module. This can even work on arity (ensure that the right
arity is mocked out). It cannot, unfortunately, help with the input or output not being
real. Engineers must be on the lookout for these issues and &lt;em&gt;diligently&lt;/em&gt; use mocking,
ensuring that the usage is correct at write-time and also after any refactors.&lt;/p&gt;

&lt;p&gt;I haven&amp;rsquo;t done so, but my guess is that typespecs might be able to help out here. I don&amp;rsquo;t
see any obvious integrations with Mockery, but anything is possible and could be implemented
custom based on the typespec metadata.&lt;/p&gt;

&lt;h2&gt;Why Mockery over others?&lt;/h2&gt;

&lt;p&gt;I had some problems with other mocking tools that dynamically switch out modules
globally. These types of tools require that test processes run synchronously rather
than asynchronously. This is not a big deal for small test suites, but could be a huge
limiter for a large test suite. At the scale of our product, I have to assume that a
service could become large over time, and so I&amp;rsquo;m very careful about test speed.&lt;/p&gt;

&lt;p&gt;I also find that defining what is mockable in the module (rather than anything being
mockable via the test suite) allows my code to be more readable and explicit. All of
a sudden, I can tell exactly what is mockable rather than assuming that anything is
mockable. If I saw someone mocking an &lt;code&gt;Enum&lt;/code&gt; function, for example, I would have
an immediate red flag raised. Seeing this play out in the module rather than the
test really does help.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading the 15th post in my 28 days of Elixir. Keep up through the month of February to see if I can
stand subjecting myself to &lt;a href="/tags/28-days-of-elixir.html" target="_blank"&gt;28 days of straight writing&lt;/a&gt;. I
am looking for new topics to write about, so please reach out if there&amp;rsquo;s anything you
really want to see!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>28 Days - Intro to Elixir Enumerable</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/02/15/intro-to-elixir-enumerable.html"/>
    <id>https://stephenbussey.com/2018/02/15/intro-to-elixir-enumerable.html</id>
    <published>2018-02-15T01:41:00-05:00</published>
    <updated>2018-02-15T02:27:26-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;My co-worker Ben recently sent me a message for a blog post idea: looking at how
Enumerable is utilized by Elixir Enum module. Specifically, he told me that
all of Enum behavior can be implemented just by writing a single reduce
function. If you&amp;rsquo;re like me, you might be thinking: &amp;ldquo;what, how is this?&amp;rdquo; Let&amp;rsquo;s
dive in.&lt;/p&gt;

&lt;p&gt;The goal of today&amp;rsquo;s post isn&amp;rsquo;t around how to use Enumerable to write your own, but
rather about how Enum is implemented and how it can use such a simple Enumerable interface
to achieve all of the Enum functionality.&lt;/p&gt;

&lt;h2&gt;Enumerable Protocol&lt;/h2&gt;

&lt;p&gt;The &lt;a href="https://hexdocs.pm/elixir/Enumerable.html" target="_blank"&gt;Elixir Enumerable docs&lt;/a&gt; seem like a
good place to start this investigation. Sure enough, here we have it:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;This protocol requires four functions to be implemented, reduce/3, count/1, member?/2, and slice/1. The core of the protocol is the reduce/3 function. All other functions exist as optimizations paths for data structures that can implement certain properties in better than linear time.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Okay, so we know that only reduce/3 is required to be implemented. However, this
function has a very particular type signature to make this all possible. A picture is
worth a thousand words, so &lt;a href="https://github.com/elixir-lang/elixir/blob/e9dfa50c74488000d2c9de71e926cdd78609b3ac/lib/elixir/lib/enum.ex#L3261" target="_blank"&gt;here&lt;/a&gt;
is the reduce implementation for List:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def reduce(_,       {:halt, acc}, _fun),   do: {:halted, acc}
def reduce(list,    {:suspend, acc}, fun), do: {:suspended, acc, &amp;amp;reduce(list, &amp;amp;1, fun)}
def reduce([],      {:cont, acc}, _fun),   do: {:done, acc}
def reduce([h | t], {:cont, acc}, fun),    do: reduce(t, fun.(h, acc), fun)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The final accumulation value is returned as &lt;code&gt;{:done, term}&lt;/code&gt;. Two alternate states should be
handled: &lt;code&gt;halt&lt;/code&gt; and &lt;code&gt;suspend&lt;/code&gt;. &lt;code&gt;suspend&lt;/code&gt; in particular is a special case which is noted as
not being needed by most regular enumerables.&lt;/p&gt;

&lt;h2&gt;How is reduce/3 used?&lt;/h2&gt;

&lt;p&gt;It took me a second to realize how this singular &lt;code&gt;reduce/3&lt;/code&gt; function signature can be
used to implement all Enum functions. Let&amp;rsquo;s look at a few examples:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def any?(enumerable, fun) do
  Enumerable.reduce(enumerable, {:cont, false}, fn entry, _ -&amp;gt;
    if fun.(entry), do: {:halt, true}, else: {:cont, false}
  end)
  |&amp;gt; elem(1)
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the any? implementation, the reducer is used in such a way that it halts immediately
if the function is truthy, otherwise continuing the enumeration.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at a function that utilizes the optional &lt;code&gt;count&lt;/code&gt; Enumerable function:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;def count(enumerable) do
  case Enumerable.count(enumerable) do
    {:ok, value} when is_integer(value) -&amp;gt;
      value

    {:error, module} -&amp;gt;
      enumerable |&amp;gt; module.reduce({:cont, 0}, fn _, acc -&amp;gt; {:cont, acc + 1} end) |&amp;gt; elem(1)
  end
end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In the above Enum.count implementation, the &lt;code&gt;Enumerable.count/1&lt;/code&gt; function is invoked for the
enumerable. If it&amp;rsquo;s available and is an integer, then it&amp;rsquo;s returned. Otherwise, the reduce function
is used for a linear time count implementation. It&amp;rsquo;s possible to see how the reduce function is
used for a count, keeping an accumulator that starts at 0 and becomes acc + 1 on each enumeration.&lt;/p&gt;

&lt;p&gt;Finally, certain Enum functions rely on a set of macros defined in &lt;a href="https://github.com/elixir-lang/elixir/blob/0727eaf37dbb7f2f5b9f4e7d0ab163e655dd8a3b/lib/elixir/lib/stream/reducers.ex#L134" target="_blank"&gt;&lt;code&gt;Stream.Reducers&lt;/code&gt;&lt;/a&gt;.
These functions appear as &lt;code&gt;R.fn&lt;/code&gt; in the Enum code, as the required module is aliased as such.
The Reducers module is implemented using some interesting meta programming. If we look at the
&lt;a href="https://github.com/elixir-lang/elixir/blob/e9dfa50c74488000d2c9de71e926cdd78609b3ac/lib/elixir/lib/enum.ex#L1302" target="_blank"&gt;&lt;code&gt;map/2&lt;/code&gt; macro definition&lt;/a&gt;,
it utilizes a &lt;code&gt;next/3&lt;/code&gt; function which isn&amp;rsquo;t defined in this macro module. This is actually defined
in the &lt;a href="https://github.com/elixir-lang/elixir/blob/e9dfa50c74488000d2c9de71e926cdd78609b3ac/lib/elixir/lib/enum.ex#L241" target="_blank"&gt;Enum module&lt;/a&gt;,
and works due to macros not evaluating code at generation time, but rather at execution time. I talked
about this trait of macros in the &lt;a href="/2018/02/08/the-beauty-of-macros.html" target="_blank"&gt;Beauty of Macros&lt;/a&gt; post.&lt;/p&gt;

&lt;h2&gt;Writing Enumerable Implementations&lt;/h2&gt;

&lt;p&gt;I&amp;rsquo;m purposely keeping this post fairly light on how to implement the Enumerable protocol
in practice, there are several good resources on how to do that. Understanding the underlying
implementation is more of my focus here. However, there is benefit in looking at the Enumerable
implementation for some core types like List and Map. The Enum module
&lt;a href="https://github.com/elixir-lang/elixir/blob/e9dfa50c74488000d2c9de71e926cdd78609b3ac/lib/elixir/lib/enum.ex#L3273" target="_blank"&gt;defines these implementations&lt;/a&gt;
and they can serve as a good starting point when writing your own.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;As you find yourself wondering how Elixir is internally built, keep in mind that the
majority of Elixir is simply Elixir code. You most likely won&amp;rsquo;t need to read erlang or
C code like you may need to in other languages. The best answers to your questions and
curiosities are found in the code itself.&lt;/p&gt;

&lt;p&gt;Thanks for reading the 14th post in my 28 days of Elixir. Keep up through the month of February to see if I can
stand subjecting myself to &lt;a href="/tags/28-days-of-elixir.html" target="_blank"&gt;28 days of straight writing&lt;/a&gt;. I
am looking for new topics to write about, so please reach out if there&amp;rsquo;s anything you
really want to see!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>28 Days - Talk Recap - Elixir in Production</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/02/14/talk-recap-elixir-in-production.html"/>
    <id>https://stephenbussey.com/2018/02/14/talk-recap-elixir-in-production.html</id>
    <published>2018-02-13T21:01:00-05:00</published>
    <updated>2018-02-15T02:24:10-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;I very recently gave a talk at the Atlanta Elixir Meetup called &amp;ldquo;Elixir in Production&amp;rdquo;.
The talk was fairly broad, but focused on what is needed to talk Elixir into production
from both a personal and technical standpoint.&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;iframe
    width="560"
    height="315"
    src="https://www.youtube.com/embed/sdqct3uN6ZU"
    frameborder="0"
    allow="encrypted-media"
    allowfullscreen&gt;
  &lt;/iframe&gt;
  &lt;div&gt;
    &lt;small&gt;
      &lt;i&gt;Recording of the Atlanta Meetup&lt;/i&gt;
    &lt;/small&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;h2&gt;Human Element&lt;/h2&gt;

&lt;p&gt;One of the prevailing messages that I focus on is that the decision to use a
technology is not just about working out technical challenges and mastering
the technology over time. Rather, I think that the &amp;ldquo;human element&amp;rdquo; needs to
be considered early and often.&lt;/p&gt;

&lt;p&gt;As an overarching theme, empathy and caring for others on the team is crucial.
All objectives and goals should keep the engineers on the team in mind. Questions like
&amp;ldquo;how will this affect my day to day&amp;rdquo; or &amp;ldquo;what mentorship will be available for me&amp;rdquo;
should be considered in putting together any timelines.&lt;/p&gt;

&lt;p&gt;In order to establish a healthy level of expertise and mentorship, I break down
two distinct roles which are useful in rolling out a new language: champions and helpers.
The champion (1-2 per team) are going to focus on overcoming any obstacles to roll out the
new technology. Champions are people who can stand to be interrupted to help out others
on the team. On top of champions, helpers who help out with questions and expertise
are established as the technology is implemented.&lt;/p&gt;

&lt;p&gt;As team members gain knowledge, expertise, and motivation behind the new tech, critical
mass can be established. Use this to accelerate the objectives and bring more team members
into the mix.&lt;/p&gt;

&lt;h2&gt;Tech Element&lt;/h2&gt;

&lt;p&gt;Of course, the human element isn&amp;rsquo;t everything. There is ideation, implementation, and maintenance
to be conquered in bringing Elixir to the organization.&lt;/p&gt;

&lt;p&gt;Existing technology requirements should be considered early. In established technology stacks,
some pieces are going to be non-negotiable. There may be proprietary authentication systems,
databases, etc which need to be integrated with from day 1. Knowing about these and planning
for them early, rather than by surprise later, may help speed along the process.&lt;/p&gt;

&lt;p&gt;I have really enjoyed two different articles by Hamidreza Soleimani:
&lt;a href="https://hamidreza-s.github.io/erlang/scheduling/real-time/preemptive/migration/2016/02/09/erlang-scheduler-details.html" target="_blank"&gt;Erlang Scheduler Details and Why It Matters&lt;/a&gt; and
&lt;a href="https://hamidreza-s.github.io/erlang%20garbage%20collection%20memory%20layout%20soft%20realtime/2015/08/24/erlang-garbage-collection-details-and-why-it-matters.html" target="_blank"&gt;Erlang Garbage Collection Details and Why It Matters&lt;/a&gt;. I found both of these posts to be among the best in terms of
understanding core parts of the erlang runtime.&lt;/p&gt;

&lt;p&gt;Finally, there are operational needs from deploying the app to maintaining it in production.
These differ greatly based on an organization, but there are some clear patterns that win out
in Elixir. Whatever you end up with, I would expect high upfront cost followed by quicker
times in the future.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading the 13th post in my 28 days of Elixir. Keep up through the month of February to see if I can
stand subjecting myself to &lt;a href="/tags/28-days-of-elixir.html" target="_blank"&gt;28 days of straight writing&lt;/a&gt;. I
am looking for new topics to write about, so please reach out if there&amp;rsquo;s anything you
really want to see!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>28 Days - Debounce websocket messages</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/02/13/debounce-websocket-messages.html"/>
    <id>https://stephenbussey.com/2018/02/13/debounce-websocket-messages.html</id>
    <published>2018-02-12T23:09:00-05:00</published>
    <updated>2018-02-12T23:53:43-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;Today I&amp;rsquo;ll finish up the current string of websocket content that I have planned.
I&amp;rsquo;ll be sharing a really neat technique that I have used in situations where I want
to keep a frontend up to date with live content, but the live content comes in
much faster than I want to update. In my situation, I desired a technique to
&amp;ldquo;debounce&amp;rdquo; these messages. That is, I want to trigger 1 message every N seconds.&lt;/p&gt;

&lt;p&gt;Special thanks to my co-worker &lt;a href="https://github.com/sionide21" target="_blank"&gt;Ben Olive&lt;/a&gt; for the
idea of this technique. He is the brains behind a lot of cool techniques that have
proven to me the power of Elixir.&lt;/p&gt;

&lt;h2&gt;Debouncing&lt;/h2&gt;

&lt;p&gt;Debouncing is a technique to limit the amount of requests made to a function in a
limited amount of time. What I&amp;rsquo;ll demonstrate is leading edge debouncing. This means
that the first message will immediately trigger, and every future event will occur
5s after the previous message. This all &amp;ldquo;resets&amp;rdquo; after 5 seconds without messages.&lt;/p&gt;

&lt;p&gt;Here is a state diagram that Ben had put together awhile ago to demonstate how this
can work:&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/debounce-websockets/diagram.png" alt="State machine for debouncing" /&gt;
  &lt;div&gt;
    &lt;small&gt;
      &lt;i&gt;The state machine for debouncing&lt;/i&gt;
    &lt;/small&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;The starting state is &amp;ldquo;idle&amp;rdquo;. When the function is called, the state enters &amp;ldquo;debouncing&amp;rdquo;, and
also applies the function. If the function is called from this state, it enters a &amp;ldquo;called&amp;rdquo; state,
but does not apply the function. From here, a X-second timeout will switch the state and
apply the function. When the &amp;ldquo;debouncing&amp;rdquo; state is exited from a timeout, the entire
state machine resets back to the initial.&lt;/p&gt;

&lt;h2&gt;Applied to Websockets&lt;/h2&gt;

&lt;p&gt;Now that there is a state diagram which represents what we need to code, the act of
coding it and knowing it is correct becomes much simpler. I personally had a ton of
trouble understanding what &amp;ldquo;debouncing&amp;rdquo; actually is, and having the reference made
implementation much simpler.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve put an entire implementation commit on &lt;a href="https://github.com/sb8244/websocket-demo/commit/18dac56092ed6f495270a5316d246c655dd88d90" target="_blank"&gt;github&lt;/a&gt;.
There is a good bit of code in such a simple concept, but each bit of code is fairly
small and relates to a step of the state machine diagram. Tests also accompany the
implementation.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t think that going in detail on the implementation will be much value, it is
fairly self contained. However, some of the testing is actually more interesting than
the debounce code. In particular, you&amp;rsquo;ll notice that I decided to setup the state machine
by calling &lt;code&gt;broadcast_from!&lt;/code&gt; rather than changing the state manually. I feel that this
gives the best &amp;ldquo;end usage&amp;rdquo; representation of the code, rather than an artifical test setup.
In addition, I do lay back on reading the socket state to get the updated assignment
values. There may be a better way to do this.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;I hope you find this technique useful if you run into a similar use case. There may
even be opportunity to turn something like this into a library which can be used
more general purpose.&lt;/p&gt;

&lt;p&gt;Thanks for reading the 12th post in my 28 days of Elixir. Keep up through the month of February to see if I can
stand subjecting myself to &lt;a href="/tags/28-days-of-elixir.html" target="_blank"&gt;28 days of straight writing&lt;/a&gt;. I
am looking for new topics to write about, so please reach out if there&amp;rsquo;s anything you
really want to see!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>28 days - Phoenix websocket HTTP breakdown</title>
    <link rel="alternate" href="https://stephenbussey.com/2018/02/12/phoenix-websocket-http-breakdown.html"/>
    <id>https://stephenbussey.com/2018/02/12/phoenix-websocket-http-breakdown.html</id>
    <published>2018-02-11T20:01:00-05:00</published>
    <updated>2018-02-11T20:26:52-05:00</updated>
    <author>
      <name>Stephen Bussey</name>
    </author>
    <content type="html">&lt;p&gt;This post is coming right on the heels of a &lt;a href="/2018/02/10/phoenix-websocket-dive.html" target="_blank"&gt;websocket post&lt;/a&gt; written yesterday.
While that post handled what a channel looks like when Phoenix websockets are used,
it doesn&amp;rsquo;t cover much of how Phoenix operates under the hood.&lt;/p&gt;

&lt;p&gt;This topic came up as I was trying to figure out how to put a plug in front of
the websocket connection, in order to have custom origin validation code. I was
surprised that I cannot put a plug in front of it, as it&amp;rsquo;s not part of the typical
Phoenix path.&lt;/p&gt;

&lt;h2&gt;Websocket HTTP Request&lt;/h2&gt;

&lt;p&gt;When a client connects to a websocket server, the initial connection is
done as http, followed by protocol switching to ws (or https/wss). This web request
does the &lt;a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API/Writing_WebSocket_servers#The_WebSocket_Handshake" target="_blank"&gt;websocket handshake&lt;/a&gt;
and ends with a connected websocket. It is possible to make this request yourself using curl (right click websocket request
in Chrome and &amp;ldquo;copy as curl&amp;rdquo;), although you will end up with a 400 bad request.&lt;/p&gt;

&lt;p&gt;As this is just a web request, we can be pretty confident that Phoenix is going to handle
it. My first thought was to figure out what the &lt;code&gt;socket&lt;/code&gt; macro in Phoenix.Endpoint
does.&lt;/p&gt;

&lt;h2&gt;Phoenix Setup&lt;/h2&gt;

&lt;p&gt;&lt;a href="https://github.com/phoenixframework/phoenix/blob/7c67edeec4e877b71a54606db33fa650e9819ca7/lib/phoenix/endpoint.ex#L754" target="_blank"&gt;&lt;code&gt;Phoenix.Endpoint&lt;/code&gt;&lt;/a&gt;
exposes a socket macro that adds the path and module to a module attribute. This
attribute is exposed as &lt;code&gt;__sockets__/0&lt;/code&gt; on the endpoint implementation.&lt;/p&gt;

&lt;p&gt;Next up, we can look at where &lt;code&gt;__sockets__&lt;/code&gt; is referenced in the Phoenix codebase:&lt;/p&gt;

&lt;div style="text-align: center"&gt;
  &lt;img src="/images/socket-http/socket-search.png" alt="__sockets__ usage from Github" /&gt;
  &lt;div&gt;
    &lt;small&gt;
      &lt;i&gt;There are only 2 users of the sockets function&lt;/i&gt;
    &lt;/small&gt;
  &lt;/div&gt;
&lt;/div&gt;

&lt;p&gt;I checked my version of cowboy in mix.lock to find out that I&amp;rsquo;m on cowboy 1. So let&amp;rsquo;s
dive into that code.&lt;/p&gt;

&lt;p&gt;The &lt;a href="https://github.com/phoenixframework/phoenix/blob/78bb8f1e5b5fab094a6fe4d8bdc3ce7cd4a55da2/lib/phoenix/endpoint/cowboy_handler.ex#L89" target="_blank"&gt;cowboy_handler&lt;/a&gt;
is where the actual cowboy server gets started up. It&amp;rsquo;s important to pass in the right
dispatches, which execute the web logic. We can see that a custom socket based dispatch
is created for every socket defined in the endpoint. Here is what my dispatch looked like
for the repo in the previous post:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;[
  {&amp;quot;/socket/websocket&amp;quot;, Phoenix.Endpoint.CowboyWebSocket,
   {Phoenix.Transports.WebSocket,
    {WebsocketDemoWeb.Endpoint, WebsocketDemoWeb.DemoSocket, :websocket}}}
]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Finally, the &lt;a href="https://github.com/phoenixframework/phoenix/blob/78bb8f1e5b5fab094a6fe4d8bdc3ce7cd4a55da2/lib/phoenix/endpoint/cowboy_websocket.ex#L9" target="_blank"&gt;&lt;code&gt;CowboyWebSocket&lt;/code&gt;&lt;/a&gt;
handles the actual websocket request, utilizing the &lt;code&gt;Phoenix.Transports.Websocket&lt;/code&gt; module
to do the heavy lifting of deciding if the connection is allowed or not.&lt;/p&gt;

&lt;p&gt;The &lt;a href="https://github.com/phoenixframework/phoenix/blob/78bb8f1e5b5fab094a6fe4d8bdc3ce7cd4a55da2/lib/phoenix/transports/websocket.ex#L85" target="_blank"&gt;&lt;code&gt;Transports.Websocket&lt;/code&gt;&lt;/a&gt;
module is what checks the origin and decides whether the websocket is allowed or
not. All of the code up until this point has been entirely within Phoenix&amp;rsquo;s framework,
without any clear cut place to hook into. Thus, I came to the conclusion that
I can&amp;rsquo;t just shimmy some new &lt;code&gt;check_origin&lt;/code&gt; logic into the code path. Ah well,
at least there was good learning.&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Thanks for reading the 11th post in my 28 days of Elixir. Keep up through the month of February to see if I can
stand subjecting myself to &lt;a href="/tags/28-days-of-elixir.html" target="_blank"&gt;28 days of straight writing&lt;/a&gt;. I
am looking for new topics to write about, so please reach out if there&amp;rsquo;s anything you
really want to see!&lt;/p&gt;
</content>
  </entry>
</feed>
